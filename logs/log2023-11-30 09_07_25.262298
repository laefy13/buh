2023-11-30 09:07:25,311 Training with a single process on 1 device (cuda:0).
2023-11-30 09:07:25,528 Model efficientnet_b0 created, param count:7664526
2023-11-30 09:07:25,529 Data processing configuration for current model + dataset:
2023-11-30 09:07:25,529 	input_size: (3, 275, 275)
2023-11-30 09:07:25,529 	interpolation: bicubic
2023-11-30 09:07:25,529 	mean: (0.485, 0.456, 0.406)
2023-11-30 09:07:25,529 	std: (0.229, 0.224, 0.225)
2023-11-30 09:07:25,529 	crop_pct: 0.875
2023-11-30 09:07:25,529 	crop_mode: center
2023-11-30 09:07:28,026 AMP not enabled. Training in float32.
2023-11-30 09:07:28,071 Scheduled epochs: 1. LR stepped per epoch.
2023-11-30 09:07:30,189 FLOPs: 33.675564032 GFLOPs
2023-11-30 09:07:31,101 Train: 0 [   0/39 (  0%)]  Loss: 1.74 (1.74)  Time: 3.027s,   10.57/s  (3.027s,   10.57/s)  LR: 1.000e-05  Data: 0.991 (0.991)
2023-11-30 09:07:31,338 Train: 0 [   1/39 (  3%)]  Loss: 3.54 (2.64)  Time: 0.237s,  135.08/s  (1.632s,   19.61/s)  LR: 1.000e-05  Data: 0.004 (0.498)
2023-11-30 09:07:31,575 Train: 0 [   2/39 (  5%)]  Loss: 1.12 (2.13)  Time: 0.237s,  135.00/s  (1.167s,   27.42/s)  LR: 1.000e-05  Data: 0.003 (0.333)
2023-11-30 09:07:31,817 Train: 0 [   3/39 (  8%)]  Loss: 3.04 (2.36)  Time: 0.243s,  131.89/s  (0.936s,   34.19/s)  LR: 1.000e-05  Data: 0.009 (0.252)
2023-11-30 09:07:32,056 Train: 0 [   4/39 ( 11%)]  Loss: 3.64 (2.62)  Time: 0.238s,  134.20/s  (0.796s,   40.18/s)  LR: 1.000e-05  Data: 0.005 (0.202)
2023-11-30 09:07:32,292 Train: 0 [   5/39 ( 13%)]  Loss: 2.81 (2.65)  Time: 0.236s,  135.33/s  (0.703s,   45.51/s)  LR: 1.000e-05  Data: 0.003 (0.169)
2023-11-30 09:07:32,529 Train: 0 [   6/39 ( 16%)]  Loss: 1.54 (2.49)  Time: 0.237s,  135.27/s  (0.636s,   50.28/s)  LR: 1.000e-05  Data: 0.003 (0.145)
2023-11-30 09:07:32,769 Train: 0 [   7/39 ( 18%)]  Loss: 1.97 (2.43)  Time: 0.241s,  133.03/s  (0.587s,   54.52/s)  LR: 1.000e-05  Data: 0.006 (0.128)
2023-11-30 09:07:33,007 Train: 0 [   8/39 ( 21%)]  Loss: 1.66 (2.34)  Time: 0.237s,  134.91/s  (0.548s,   58.38/s)  LR: 1.000e-05  Data: 0.003 (0.114)
2023-11-30 09:07:33,247 Train: 0 [   9/39 ( 24%)]  Loss: 2.16 (2.32)  Time: 0.240s,  133.31/s  (0.517s,   61.86/s)  LR: 1.000e-05  Data: 0.005 (0.103)
2023-11-30 09:07:33,485 Train: 0 [  10/39 ( 26%)]  Loss: 1.48 (2.25)  Time: 0.239s,  134.10/s  (0.492s,   65.05/s)  LR: 1.000e-05  Data: 0.005 (0.094)
2023-11-30 09:07:33,724 Train: 0 [  11/39 ( 29%)]  Loss: 3.74 (2.37)  Time: 0.239s,  133.98/s  (0.471s,   67.96/s)  LR: 1.000e-05  Data: 0.005 (0.087)
2023-11-30 09:07:33,964 Train: 0 [  12/39 ( 32%)]  Loss: 1.32 (2.29)  Time: 0.240s,  133.33/s  (0.453s,   70.62/s)  LR: 1.000e-05  Data: 0.005 (0.080)
2023-11-30 09:07:34,205 Train: 0 [  13/39 ( 34%)]  Loss: 1.86 (2.26)  Time: 0.241s,  132.66/s  (0.438s,   73.06/s)  LR: 1.000e-05  Data: 0.005 (0.075)
2023-11-30 09:07:34,444 Train: 0 [  14/39 ( 37%)]  Loss: 3.96 (2.37)  Time: 0.239s,  134.07/s  (0.425s,   75.35/s)  LR: 1.000e-05  Data: 0.005 (0.070)
2023-11-30 09:07:34,682 Train: 0 [  15/39 ( 39%)]  Loss: 1.47 (2.32)  Time: 0.239s,  134.17/s  (0.413s,   77.47/s)  LR: 1.000e-05  Data: 0.005 (0.066)
2023-11-30 09:07:34,921 Train: 0 [  16/39 ( 42%)]  Loss: 1.25 (2.25)  Time: 0.239s,  134.03/s  (0.403s,   79.44/s)  LR: 1.000e-05  Data: 0.005 (0.063)
2023-11-30 09:07:35,160 Train: 0 [  17/39 ( 45%)]  Loss: 1.05 (2.19)  Time: 0.239s,  133.93/s  (0.394s,   81.28/s)  LR: 1.000e-05  Data: 0.005 (0.059)
2023-11-30 09:07:35,399 Train: 0 [  18/39 ( 47%)]  Loss: 0.993 (2.12)  Time: 0.239s,  134.03/s  (0.386s,   83.00/s)  LR: 1.000e-05  Data: 0.005 (0.057)
2023-11-30 09:07:35,638 Train: 0 [  19/39 ( 50%)]  Loss: 2.42 (2.14)  Time: 0.239s,  133.88/s  (0.378s,   84.61/s)  LR: 1.000e-05  Data: 0.005 (0.054)
2023-11-30 09:07:35,877 Train: 0 [  20/39 ( 53%)]  Loss: 2.18 (2.14)  Time: 0.239s,  134.08/s  (0.372s,   86.12/s)  LR: 1.000e-05  Data: 0.005 (0.052)
2023-11-30 09:07:36,115 Train: 0 [  21/39 ( 55%)]  Loss: 1.94 (2.13)  Time: 0.239s,  134.09/s  (0.366s,   87.54/s)  LR: 1.000e-05  Data: 0.005 (0.050)
2023-11-30 09:07:36,355 Train: 0 [  22/39 ( 58%)]  Loss: 1.01 (2.08)  Time: 0.239s,  133.74/s  (0.360s,   88.88/s)  LR: 1.000e-05  Data: 0.005 (0.048)
2023-11-30 09:07:36,593 Train: 0 [  23/39 ( 61%)]  Loss: 1.15 (2.04)  Time: 0.238s,  134.25/s  (0.355s,   90.15/s)  LR: 1.000e-05  Data: 0.005 (0.046)
2023-11-30 09:07:36,831 Train: 0 [  24/39 ( 63%)]  Loss: 3.36 (2.10)  Time: 0.239s,  134.11/s  (0.350s,   91.35/s)  LR: 1.000e-05  Data: 0.005 (0.044)
2023-11-30 09:07:37,071 Train: 0 [  25/39 ( 66%)]  Loss: 0.945 (2.05)  Time: 0.239s,  133.81/s  (0.346s,   92.48/s)  LR: 1.000e-05  Data: 0.005 (0.043)
2023-11-30 09:07:37,309 Train: 0 [  26/39 ( 68%)]  Loss: 0.758 (2.00)  Time: 0.238s,  134.27/s  (0.342s,   93.55/s)  LR: 1.000e-05  Data: 0.005 (0.041)
2023-11-30 09:07:37,548 Train: 0 [  27/39 ( 71%)]  Loss: 1.47 (1.99)  Time: 0.239s,  134.10/s  (0.338s,   94.58/s)  LR: 1.000e-05  Data: 0.005 (0.040)
2023-11-30 09:07:37,786 Train: 0 [  28/39 ( 74%)]  Loss: 2.86 (2.02)  Time: 0.239s,  134.01/s  (0.335s,   95.54/s)  LR: 1.000e-05  Data: 0.005 (0.039)
2023-11-30 09:07:38,026 Train: 0 [  29/39 ( 76%)]  Loss: 0.703 (1.97)  Time: 0.239s,  133.78/s  (0.332s,   96.46/s)  LR: 1.000e-05  Data: 0.005 (0.038)
2023-11-30 09:07:38,264 Train: 0 [  30/39 ( 79%)]  Loss: 1.04 (1.94)  Time: 0.238s,  134.33/s  (0.329s,   97.35/s)  LR: 1.000e-05  Data: 0.005 (0.037)
2023-11-30 09:07:38,502 Train: 0 [  31/39 ( 82%)]  Loss: 1.78 (1.94)  Time: 0.238s,  134.60/s  (0.326s,   98.20/s)  LR: 1.000e-05  Data: 0.005 (0.036)
2023-11-30 09:07:38,739 Train: 0 [  32/39 ( 84%)]  Loss: 1.79 (1.93)  Time: 0.238s,  134.56/s  (0.323s,   99.01/s)  LR: 1.000e-05  Data: 0.005 (0.035)
2023-11-30 09:07:38,976 Train: 0 [  33/39 ( 87%)]  Loss: 1.92 (1.93)  Time: 0.237s,  134.94/s  (0.321s,   99.79/s)  LR: 1.000e-05  Data: 0.005 (0.034)
2023-11-30 09:07:39,214 Train: 0 [  34/39 ( 89%)]  Loss: 1.05 (1.91)  Time: 0.237s,  134.87/s  (0.318s,  100.54/s)  LR: 1.000e-05  Data: 0.004 (0.033)
2023-11-30 09:07:39,453 Train: 0 [  35/39 ( 92%)]  Loss: 1.04 (1.88)  Time: 0.239s,  133.80/s  (0.316s,  101.24/s)  LR: 1.000e-05  Data: 0.004 (0.032)
2023-11-30 09:07:39,691 Train: 0 [  36/39 ( 95%)]  Loss: 0.795 (1.85)  Time: 0.238s,  134.66/s  (0.314s,  101.92/s)  LR: 1.000e-05  Data: 0.004 (0.031)
2023-11-30 09:07:39,928 Train: 0 [  37/39 ( 97%)]  Loss: 2.62 (1.87)  Time: 0.238s,  134.70/s  (0.312s,  102.58/s)  LR: 1.000e-05  Data: 0.005 (0.031)
2023-11-30 09:07:40,161 Train: 0 [  38/39 (100%)]  Loss: 0.776 (1.85)  Time: 0.233s,  137.43/s  (0.310s,  103.25/s)  LR: 1.000e-05  Data: 0.000 (0.030)
2023-11-30 09:07:41,333 Test: [   0/39]  Time: 1.168 (1.168)  Loss:   0.884 ( 0.884)  Acc@1:   0.000 (  0.000)  Acc@5: 100.000 (100.000)precision:   0.000 (  0.000)recall:   0.000 (  0.000)soec:   0.000 (  0.000)f1:   0.000 (  0.000)
2023-11-30 09:07:41,391 Test: [   1/39]  Time: 0.058 (0.613)  Loss:   0.888 ( 0.886)  Acc@1:   0.000 (  0.000)  Acc@5: 100.000 (100.000)precision:   0.000 (  0.000)recall:   0.000 (  0.000)soec:   0.000 (  0.000)f1:   0.000 (  0.000)
2023-11-30 09:07:41,448 Test: [   2/39]  Time: 0.058 (0.428)  Loss:   0.890 ( 0.887)  Acc@1:   0.000 (  0.000)  Acc@5: 100.000 (100.000)precision:   0.000 (  0.000)recall:   0.000 (  0.000)soec:   0.000 (  0.000)f1:   0.000 (  0.000)
2023-11-30 09:07:41,831 Test: [   3/39]  Time: 0.383 (0.417)  Loss:   0.897 ( 0.890)  Acc@1:   0.000 (  0.000)  Acc@5: 100.000 (100.000)precision:   0.000 (  0.000)recall:   0.000 (  0.000)soec:   0.000 (  0.000)f1:   0.000 (  0.000)
2023-11-30 09:07:41,973 Test: [   4/39]  Time: 0.143 (0.362)  Loss:   0.891 ( 0.890)  Acc@1:   0.000 (  0.000)  Acc@5: 100.000 (100.000)precision:   0.000 (  0.000)recall:   0.000 (  0.000)soec:   0.000 (  0.000)f1:   0.000 (  0.000)
2023-11-30 09:07:42,031 Test: [   5/39]  Time: 0.058 (0.311)  Loss:   0.889 ( 0.890)  Acc@1:   0.000 (  0.000)  Acc@5: 100.000 (100.000)precision:   0.000 (  0.000)recall:   0.000 (  0.000)soec:   0.000 (  0.000)f1:   0.000 (  0.000)
2023-11-30 09:07:42,089 Test: [   6/39]  Time: 0.058 (0.275)  Loss:   0.886 ( 0.889)  Acc@1:   0.000 (  0.000)  Acc@5: 100.000 (100.000)precision:   0.000 (  0.000)recall:   0.000 (  0.000)soec:   0.000 (  0.000)f1:   0.000 (  0.000)
2023-11-30 09:07:42,435 Test: [   7/39]  Time: 0.346 (0.284)  Loss:   0.884 ( 0.889)  Acc@1:   0.000 (  0.000)  Acc@5: 100.000 (100.000)precision:   0.000 (  0.000)recall:   0.000 (  0.000)soec:   0.000 (  0.000)f1:   0.000 (  0.000)
2023-11-30 09:07:42,636 Test: [   8/39]  Time: 0.202 (0.275)  Loss:   0.889 ( 0.889)  Acc@1:   0.000 (  0.000)  Acc@5: 100.000 (100.000)precision:   0.000 (  0.000)recall:   0.000 (  0.000)soec:   0.000 (  0.000)f1:   0.000 (  0.000)
2023-11-30 09:07:42,694 Test: [   9/39]  Time: 0.058 (0.253)  Loss:   0.886 ( 0.888)  Acc@1:   0.000 (  0.000)  Acc@5: 100.000 (100.000)precision:   0.000 (  0.000)recall:   0.000 (  0.000)soec:   0.000 (  0.000)f1:   0.000 (  0.000)
2023-11-30 09:07:42,752 Test: [  10/39]  Time: 0.058 (0.235)  Loss:   0.889 ( 0.888)  Acc@1:   0.000 (  0.000)  Acc@5: 100.000 (100.000)precision:   0.000 (  0.000)recall:   0.000 (  0.000)soec:   0.000 (  0.000)f1:   0.000 (  0.000)
2023-11-30 09:07:43,085 Test: [  11/39]  Time: 0.334 (0.243)  Loss:   0.870 ( 0.887)  Acc@1:   0.000 (  0.000)  Acc@5: 100.000 (100.000)precision:   0.000 (  0.000)recall:   0.000 (  0.000)soec:   0.000 (  0.000)f1:   0.000 (  0.000)
2023-11-30 09:07:43,294 Test: [  12/39]  Time: 0.208 (0.241)  Loss:   0.880 ( 0.886)  Acc@1:   0.000 (  0.000)  Acc@5: 100.000 (100.000)precision:   0.000 (  0.000)recall:   0.000 (  0.000)soec:   0.000 (  0.000)f1:   0.000 (  0.000)
2023-11-30 09:07:43,351 Test: [  13/39]  Time: 0.057 (0.228)  Loss:   0.876 ( 0.886)  Acc@1:   0.000 (  0.000)  Acc@5: 100.000 (100.000)precision:   0.000 (  0.000)recall:   0.000 (  0.000)soec:   0.000 (  0.000)f1:   0.000 (  0.000)
2023-11-30 09:07:43,409 Test: [  14/39]  Time: 0.058 (0.216)  Loss:   0.881 ( 0.885)  Acc@1:   0.000 (  0.000)  Acc@5: 100.000 (100.000)precision:   0.000 (  0.000)recall:   0.000 (  0.000)soec:   0.000 (  0.000)f1:   0.000 (  0.000)
2023-11-30 09:07:43,760 Test: [  15/39]  Time: 0.352 (0.225)  Loss:   0.892 ( 0.886)  Acc@1:   0.000 (  0.000)  Acc@5: 100.000 (100.000)precision:   0.000 (  0.000)recall:   0.000 (  0.000)soec:   0.000 (  0.000)f1:   0.000 (  0.000)
2023-11-30 09:07:43,962 Test: [  16/39]  Time: 0.201 (0.223)  Loss:   0.884 ( 0.886)  Acc@1:   0.000 (  0.000)  Acc@5: 100.000 (100.000)precision:   0.000 (  0.000)recall:   0.000 (  0.000)soec:   0.000 (  0.000)f1:   0.000 (  0.000)
2023-11-30 09:07:44,019 Test: [  17/39]  Time: 0.057 (0.214)  Loss:   0.882 ( 0.885)  Acc@1:   0.000 (  0.000)  Acc@5: 100.000 (100.000)precision:   0.000 (  0.000)recall:   0.000 (  0.000)soec:   0.000 (  0.000)f1:   0.000 (  0.000)
2023-11-30 09:07:44,077 Test: [  18/39]  Time: 0.058 (0.206)  Loss:   0.874 ( 0.885)  Acc@1:   0.000 (  0.000)  Acc@5: 100.000 (100.000)precision:   0.000 (  0.000)recall:   0.000 (  0.000)soec:   0.000 (  0.000)f1:   0.000 (  0.000)
2023-11-30 09:07:44,376 Test: [  19/39]  Time: 0.299 (0.211)  Loss:   0.890 ( 0.885)  Acc@1:   0.000 (  0.000)  Acc@5: 100.000 (100.000)precision:   0.000 (  0.000)recall:   0.000 (  0.000)soec:   0.000 (  0.000)f1:   0.000 (  0.000)
2023-11-30 09:07:44,599 Test: [  20/39]  Time: 0.223 (0.211)  Loss:   0.896 ( 0.886)  Acc@1:   0.000 (  0.000)  Acc@5: 100.000 (100.000)precision:   0.000 (  0.000)recall:   0.000 (  0.000)soec:   0.000 (  0.000)f1:   0.000 (  0.000)
2023-11-30 09:07:44,656 Test: [  21/39]  Time: 0.058 (0.204)  Loss:   0.882 ( 0.885)  Acc@1:   0.000 (  0.000)  Acc@5: 100.000 (100.000)precision:   0.000 (  0.000)recall:   0.000 (  0.000)soec:   0.000 (  0.000)f1:   0.000 (  0.000)
2023-11-30 09:07:44,714 Test: [  22/39]  Time: 0.058 (0.198)  Loss:   0.623 ( 0.874)  Acc@1:  71.875 (  3.125)  Acc@5: 100.000 (100.000)precision:   0.742 (  0.032)recall:   0.958 (  0.042)soec:   0.000 (  0.000)f1:   0.836 (  0.036)
2023-11-30 09:07:44,994 Test: [  23/39]  Time: 0.281 (0.201)  Loss:   0.520 ( 0.859)  Acc@1: 100.000 (  7.161)  Acc@5: 100.000 (100.000)precision:   1.000 (  0.073)recall:   1.000 (  0.082)soec:   0.000 (  0.000)f1:   1.000 (  0.077)
2023-11-30 09:07:45,256 Test: [  24/39]  Time: 0.262 (0.204)  Loss:   0.528 ( 0.846)  Acc@1: 100.000 ( 10.875)  Acc@5: 100.000 (100.000)precision:   1.000 (  0.110)recall:   1.000 (  0.118)soec:   0.000 (  0.000)f1:   1.000 (  0.113)
2023-11-30 09:07:45,314 Test: [  25/39]  Time: 0.058 (0.198)  Loss:   0.521 ( 0.834)  Acc@1: 100.000 ( 14.303)  Acc@5: 100.000 (100.000)precision:   1.000 (  0.144)recall:   1.000 (  0.152)soec:   0.000 (  0.000)f1:   1.000 (  0.148)
2023-11-30 09:07:45,372 Test: [  26/39]  Time: 0.058 (0.193)  Loss:   0.524 ( 0.822)  Acc@1: 100.000 ( 17.477)  Acc@5: 100.000 (100.000)precision:   1.000 (  0.176)recall:   1.000 (  0.184)soec:   0.000 (  0.000)f1:   1.000 (  0.179)
2023-11-30 09:07:45,634 Test: [  27/39]  Time: 0.263 (0.195)  Loss:   0.520 ( 0.811)  Acc@1: 100.000 ( 20.424)  Acc@5: 100.000 (100.000)precision:   1.000 (  0.205)recall:   1.000 (  0.213)soec:   0.000 (  0.000)f1:   1.000 (  0.208)
2023-11-30 09:07:45,859 Test: [  28/39]  Time: 0.225 (0.196)  Loss:   0.526 ( 0.801)  Acc@1: 100.000 ( 23.168)  Acc@5: 100.000 (100.000)precision:   1.000 (  0.232)recall:   1.000 (  0.240)soec:   0.000 (  0.000)f1:   1.000 (  0.236)
2023-11-30 09:07:45,916 Test: [  29/39]  Time: 0.058 (0.192)  Loss:   0.529 ( 0.792)  Acc@1: 100.000 ( 25.729)  Acc@5: 100.000 (100.000)precision:   1.000 (  0.258)recall:   1.000 (  0.265)soec:   0.000 (  0.000)f1:   1.000 (  0.261)
2023-11-30 09:07:45,974 Test: [  30/39]  Time: 0.058 (0.187)  Loss:   0.529 ( 0.784)  Acc@1: 100.000 ( 28.125)  Acc@5: 100.000 (100.000)precision:   1.000 (  0.282)recall:   1.000 (  0.289)soec:   0.000 (  0.000)f1:   1.000 (  0.285)
2023-11-30 09:07:46,261 Test: [  31/39]  Time: 0.287 (0.191)  Loss:   0.526 ( 0.776)  Acc@1: 100.000 ( 30.371)  Acc@5: 100.000 (100.000)precision:   1.000 (  0.304)recall:   1.000 (  0.311)soec:   0.000 (  0.000)f1:   1.000 (  0.307)
2023-11-30 09:07:46,477 Test: [  32/39]  Time: 0.217 (0.191)  Loss:   0.525 ( 0.768)  Acc@1: 100.000 ( 32.481)  Acc@5: 100.000 (100.000)precision:   1.000 (  0.326)recall:   1.000 (  0.332)soec:   0.000 (  0.000)f1:   1.000 (  0.328)
2023-11-30 09:07:46,535 Test: [  33/39]  Time: 0.057 (0.187)  Loss:   0.529 ( 0.761)  Acc@1: 100.000 ( 34.467)  Acc@5: 100.000 (100.000)precision:   1.000 (  0.345)recall:   1.000 (  0.352)soec:   0.000 (  0.000)f1:   1.000 (  0.348)
2023-11-30 09:07:46,592 Test: [  34/39]  Time: 0.058 (0.184)  Loss:   0.519 ( 0.754)  Acc@1: 100.000 ( 36.339)  Acc@5: 100.000 (100.000)precision:   1.000 (  0.364)recall:   1.000 (  0.370)soec:   0.000 (  0.000)f1:   1.000 (  0.367)
2023-11-30 09:07:46,651 Test: [  35/39]  Time: 0.059 (0.180)  Loss:   0.526 ( 0.748)  Acc@1: 100.000 ( 38.108)  Acc@5: 100.000 (100.000)precision:   1.000 (  0.382)recall:   1.000 (  0.388)soec:   0.000 (  0.000)f1:   1.000 (  0.384)
2023-11-30 09:07:46,988 Test: [  36/39]  Time: 0.337 (0.184)  Loss:   0.607 ( 0.744)  Acc@1:  78.125 ( 39.189)  Acc@5: 100.000 (100.000)precision:   1.000 (  0.398)recall:   0.781 (  0.398)soec:   0.000 (  0.000)f1:   0.877 (  0.398)
2023-11-30 09:07:47,584 Test: [  37/39]  Time: 0.596 (0.195)  Loss:   0.581 ( 0.740)  Acc@1:  81.250 ( 40.296)  Acc@5: 100.000 (100.000)precision:   1.000 (  0.414)recall:   0.812 (  0.409)soec:   0.000 (  0.000)f1:   0.897 (  0.411)
2023-11-30 09:07:47,639 Test: [  38/39]  Time: 0.055 (0.192)  Loss:   0.558 ( 0.735)  Acc@1:  96.875 ( 41.747)  Acc@5: 100.000 (100.000)precision:   1.000 (  0.429)recall:   0.969 (  0.424)soec:   0.000 (  0.000)f1:   0.984 (  0.425)
2023-11-30 09:07:47,836 Test: [  39/39]  Time: 0.197 (0.192)  Loss:   0.522 ( 0.735)  Acc@1: 100.000 ( 41.840)  Acc@5: 100.000 (100.000)precision:   1.000 (  0.430)recall:   1.000 (  0.425)soec:   0.000 (  0.000)f1:   1.000 (  0.426)
2023-11-30 09:07:48,029 Current checkpoints:
 ('./output/train/20231130-090728-efficientnet_b0-275/checkpoint-0.pth.tar', 41.84)

2023-11-30 09:07:48,029 *** Best metric: 41.84 (epoch 0)

2023-11-30 09:13:34,410 Training with a single process on 1 device (cuda:0).
2023-11-30 09:13:34,608 Model efficientnet_b0 created, param count:7664526
2023-11-30 09:13:34,608 Data processing configuration for current model + dataset:
2023-11-30 09:13:34,608 	input_size: (3, 275, 275)
2023-11-30 09:13:34,608 	interpolation: bicubic
2023-11-30 09:13:34,608 	mean: (0.485, 0.456, 0.406)
2023-11-30 09:13:34,608 	std: (0.229, 0.224, 0.225)
2023-11-30 09:13:34,608 	crop_pct: 0.875
2023-11-30 09:13:34,608 	crop_mode: center
2023-11-30 09:13:37,051 AMP not enabled. Training in float32.
2023-11-30 09:13:37,093 Scheduled epochs: 1. LR stepped per epoch.
2023-11-30 09:13:39,071 FLOPs: 33.675564032 GFLOPs
2023-11-30 09:13:39,964 Train: 0 [   0/39 (  0%)]  Loss: 1.74 (1.74)  Time: 2.869s,   11.16/s  (2.869s,   11.16/s)  LR: 1.000e-05  Data: 0.888 (0.888)
2023-11-30 09:13:40,202 Train: 0 [   1/39 (  3%)]  Loss: 3.54 (2.64)  Time: 0.238s,  134.46/s  (1.553s,   20.60/s)  LR: 1.000e-05  Data: 0.004 (0.446)
2023-11-30 09:13:40,439 Train: 0 [   2/39 (  5%)]  Loss: 1.12 (2.13)  Time: 0.237s,  135.15/s  (1.114s,   28.71/s)  LR: 1.000e-05  Data: 0.003 (0.298)
2023-11-30 09:13:40,677 Train: 0 [   3/39 (  8%)]  Loss: 3.04 (2.36)  Time: 0.238s,  134.18/s  (0.895s,   35.74/s)  LR: 1.000e-05  Data: 0.005 (0.225)
2023-11-30 09:13:40,920 Train: 0 [   4/39 ( 11%)]  Loss: 3.64 (2.62)  Time: 0.242s,  132.02/s  (0.765s,   41.84/s)  LR: 1.000e-05  Data: 0.009 (0.182)
2023-11-30 09:13:41,157 Train: 0 [   5/39 ( 13%)]  Loss: 2.81 (2.65)  Time: 0.237s,  135.17/s  (0.677s,   47.28/s)  LR: 1.000e-05  Data: 0.003 (0.152)
2023-11-30 09:13:41,393 Train: 0 [   6/39 ( 16%)]  Loss: 1.54 (2.49)  Time: 0.237s,  135.30/s  (0.614s,   52.12/s)  LR: 1.000e-05  Data: 0.003 (0.131)
2023-11-30 09:13:41,633 Train: 0 [   7/39 ( 18%)]  Loss: 1.97 (2.43)  Time: 0.240s,  133.55/s  (0.567s,   56.42/s)  LR: 1.000e-05  Data: 0.005 (0.115)
2023-11-30 09:13:41,871 Train: 0 [   8/39 ( 21%)]  Loss: 1.66 (2.34)  Time: 0.239s,  134.06/s  (0.531s,   60.30/s)  LR: 1.000e-05  Data: 0.005 (0.103)
2023-11-30 09:13:42,110 Train: 0 [   9/39 ( 24%)]  Loss: 2.16 (2.32)  Time: 0.238s,  134.25/s  (0.501s,   63.82/s)  LR: 1.000e-05  Data: 0.005 (0.093)
2023-11-30 09:13:42,348 Train: 0 [  10/39 ( 26%)]  Loss: 1.48 (2.25)  Time: 0.238s,  134.32/s  (0.477s,   67.02/s)  LR: 1.000e-05  Data: 0.004 (0.085)
2023-11-30 09:13:42,586 Train: 0 [  11/39 ( 29%)]  Loss: 3.74 (2.37)  Time: 0.238s,  134.29/s  (0.458s,   69.94/s)  LR: 1.000e-05  Data: 0.005 (0.078)
2023-11-30 09:13:42,825 Train: 0 [  12/39 ( 32%)]  Loss: 1.32 (2.29)  Time: 0.239s,  134.17/s  (0.441s,   72.61/s)  LR: 1.000e-05  Data: 0.005 (0.073)
2023-11-30 09:13:43,063 Train: 0 [  13/39 ( 34%)]  Loss: 1.86 (2.26)  Time: 0.239s,  134.06/s  (0.426s,   75.07/s)  LR: 1.000e-05  Data: 0.005 (0.068)
2023-11-30 09:13:43,301 Train: 0 [  14/39 ( 37%)]  Loss: 3.96 (2.37)  Time: 0.238s,  134.56/s  (0.414s,   77.35/s)  LR: 1.000e-05  Data: 0.004 (0.063)
2023-11-30 09:13:43,540 Train: 0 [  15/39 ( 39%)]  Loss: 1.48 (2.32)  Time: 0.239s,  134.13/s  (0.403s,   79.45/s)  LR: 1.000e-05  Data: 0.005 (0.060)
2023-11-30 09:13:43,778 Train: 0 [  16/39 ( 42%)]  Loss: 1.25 (2.25)  Time: 0.238s,  134.19/s  (0.393s,   81.40/s)  LR: 1.000e-05  Data: 0.005 (0.057)
2023-11-30 09:13:44,023 Train: 0 [  17/39 ( 45%)]  Loss: 1.05 (2.19)  Time: 0.244s,  131.02/s  (0.385s,   83.15/s)  LR: 1.000e-05  Data: 0.005 (0.054)
2023-11-30 09:13:44,261 Train: 0 [  18/39 ( 47%)]  Loss: 0.993 (2.12)  Time: 0.238s,  134.32/s  (0.377s,   84.85/s)  LR: 1.000e-05  Data: 0.004 (0.051)
2023-11-30 09:13:44,500 Train: 0 [  19/39 ( 50%)]  Loss: 2.42 (2.14)  Time: 0.239s,  133.74/s  (0.370s,   86.43/s)  LR: 1.000e-05  Data: 0.005 (0.049)
2023-11-30 09:13:44,745 Train: 0 [  20/39 ( 53%)]  Loss: 2.18 (2.14)  Time: 0.245s,  130.84/s  (0.364s,   87.85/s)  LR: 1.000e-05  Data: 0.009 (0.047)
2023-11-30 09:13:44,984 Train: 0 [  21/39 ( 55%)]  Loss: 1.94 (2.13)  Time: 0.239s,  133.89/s  (0.359s,   89.25/s)  LR: 1.000e-05  Data: 0.005 (0.045)
2023-11-30 09:13:45,223 Train: 0 [  22/39 ( 58%)]  Loss: 1.01 (2.08)  Time: 0.239s,  133.68/s  (0.353s,   90.56/s)  LR: 1.000e-05  Data: 0.004 (0.043)
2023-11-30 09:13:45,465 Train: 0 [  23/39 ( 61%)]  Loss: 1.15 (2.04)  Time: 0.242s,  132.16/s  (0.349s,   91.76/s)  LR: 1.000e-05  Data: 0.005 (0.042)
2023-11-30 09:13:45,704 Train: 0 [  24/39 ( 63%)]  Loss: 3.36 (2.10)  Time: 0.239s,  133.71/s  (0.344s,   92.93/s)  LR: 1.000e-05  Data: 0.006 (0.040)
2023-11-30 09:13:45,943 Train: 0 [  25/39 ( 66%)]  Loss: 0.946 (2.05)  Time: 0.239s,  134.05/s  (0.340s,   94.04/s)  LR: 1.000e-05  Data: 0.005 (0.039)
2023-11-30 09:13:46,181 Train: 0 [  26/39 ( 68%)]  Loss: 0.758 (2.00)  Time: 0.238s,  134.53/s  (0.336s,   95.10/s)  LR: 1.000e-05  Data: 0.004 (0.038)
2023-11-30 09:13:46,420 Train: 0 [  27/39 ( 71%)]  Loss: 1.48 (1.99)  Time: 0.239s,  134.02/s  (0.333s,   96.09/s)  LR: 1.000e-05  Data: 0.005 (0.036)
2023-11-30 09:13:46,658 Train: 0 [  28/39 ( 74%)]  Loss: 2.86 (2.02)  Time: 0.239s,  134.17/s  (0.330s,   97.04/s)  LR: 1.000e-05  Data: 0.005 (0.035)
2023-11-30 09:13:46,897 Train: 0 [  29/39 ( 76%)]  Loss: 0.703 (1.97)  Time: 0.239s,  134.14/s  (0.327s,   97.95/s)  LR: 1.000e-05  Data: 0.005 (0.034)
2023-11-30 09:13:47,135 Train: 0 [  30/39 ( 79%)]  Loss: 1.04 (1.94)  Time: 0.238s,  134.45/s  (0.324s,   98.81/s)  LR: 1.000e-05  Data: 0.004 (0.033)
2023-11-30 09:13:47,373 Train: 0 [  31/39 ( 82%)]  Loss: 1.78 (1.94)  Time: 0.238s,  134.31/s  (0.321s,   99.63/s)  LR: 1.000e-05  Data: 0.005 (0.032)
2023-11-30 09:13:47,610 Train: 0 [  32/39 ( 84%)]  Loss: 1.82 (1.93)  Time: 0.237s,  135.05/s  (0.319s,  100.43/s)  LR: 1.000e-05  Data: 0.004 (0.032)
2023-11-30 09:13:47,847 Train: 0 [  33/39 ( 87%)]  Loss: 1.89 (1.93)  Time: 0.237s,  134.97/s  (0.316s,  101.19/s)  LR: 1.000e-05  Data: 0.005 (0.031)
2023-11-30 09:13:48,085 Train: 0 [  34/39 ( 89%)]  Loss: 1.01 (1.91)  Time: 0.237s,  134.77/s  (0.314s,  101.92/s)  LR: 1.000e-05  Data: 0.004 (0.030)
2023-11-30 09:13:48,322 Train: 0 [  35/39 ( 92%)]  Loss: 1.06 (1.88)  Time: 0.237s,  134.98/s  (0.312s,  102.62/s)  LR: 1.000e-05  Data: 0.005 (0.029)
2023-11-30 09:13:48,559 Train: 0 [  36/39 ( 95%)]  Loss: 0.806 (1.85)  Time: 0.238s,  134.73/s  (0.310s,  103.28/s)  LR: 1.000e-05  Data: 0.005 (0.029)
2023-11-30 09:13:48,797 Train: 0 [  37/39 ( 97%)]  Loss: 2.62 (1.87)  Time: 0.238s,  134.65/s  (0.308s,  103.92/s)  LR: 1.000e-05  Data: 0.005 (0.028)
2023-11-30 09:13:49,029 Train: 0 [  38/39 (100%)]  Loss: 0.785 (1.85)  Time: 0.232s,  137.72/s  (0.306s,  104.58/s)  LR: 1.000e-05  Data: 0.000 (0.027)
2023-11-30 09:13:50,233 Test: [   0/39]  Time: 1.201 (1.201)  Loss:   0.848 ( 0.848)  Acc@1:   3.125 (  3.125)  Acc@5: 100.000 (100.000)precision:   0.000 (  0.000)recall:   0.000 (  0.000)soec:   0.031 (  0.031)f1:   0.000 (  0.000)
2023-11-30 09:13:50,292 Test: [   1/39]  Time: 0.058 (0.629)  Loss:   0.852 ( 0.850)  Acc@1:   0.000 (  1.562)  Acc@5: 100.000 (100.000)precision:   0.000 (  0.000)recall:   0.000 (  0.000)soec:   0.000 (  0.016)f1:   0.000 (  0.000)
2023-11-30 09:13:50,349 Test: [   2/39]  Time: 0.058 (0.439)  Loss:   0.853 ( 0.851)  Acc@1:   0.000 (  1.042)  Acc@5: 100.000 (100.000)precision:   0.000 (  0.000)recall:   0.000 (  0.000)soec:   0.000 (  0.010)f1:   0.000 (  0.000)
2023-11-30 09:13:50,752 Test: [   3/39]  Time: 0.403 (0.430)  Loss:   0.860 ( 0.853)  Acc@1:   0.000 (  0.781)  Acc@5: 100.000 (100.000)precision:   0.000 (  0.000)recall:   0.000 (  0.000)soec:   0.000 (  0.008)f1:   0.000 (  0.000)
2023-11-30 09:13:50,888 Test: [   4/39]  Time: 0.136 (0.371)  Loss:   0.854 ( 0.853)  Acc@1:   0.000 (  0.625)  Acc@5: 100.000 (100.000)precision:   0.000 (  0.000)recall:   0.000 (  0.000)soec:   0.000 (  0.006)f1:   0.000 (  0.000)
2023-11-30 09:13:50,945 Test: [   5/39]  Time: 0.058 (0.319)  Loss:   0.852 ( 0.853)  Acc@1:   0.000 (  0.521)  Acc@5: 100.000 (100.000)precision:   0.000 (  0.000)recall:   0.000 (  0.000)soec:   0.000 (  0.005)f1:   0.000 (  0.000)
2023-11-30 09:13:51,003 Test: [   6/39]  Time: 0.058 (0.281)  Loss:   0.849 ( 0.853)  Acc@1:   0.000 (  0.446)  Acc@5: 100.000 (100.000)precision:   0.000 (  0.000)recall:   0.000 (  0.000)soec:   0.000 (  0.004)f1:   0.000 (  0.000)
2023-11-30 09:13:51,355 Test: [   7/39]  Time: 0.352 (0.290)  Loss:   0.847 ( 0.852)  Acc@1:   0.000 (  0.391)  Acc@5: 100.000 (100.000)precision:   0.000 (  0.000)recall:   0.000 (  0.000)soec:   0.000 (  0.004)f1:   0.000 (  0.000)
2023-11-30 09:13:51,545 Test: [   8/39]  Time: 0.190 (0.279)  Loss:   0.852 ( 0.852)  Acc@1:   0.000 (  0.347)  Acc@5: 100.000 (100.000)precision:   0.000 (  0.000)recall:   0.000 (  0.000)soec:   0.000 (  0.003)f1:   0.000 (  0.000)
2023-11-30 09:13:51,603 Test: [   9/39]  Time: 0.058 (0.257)  Loss:   0.849 ( 0.852)  Acc@1:   0.000 (  0.312)  Acc@5: 100.000 (100.000)precision:   0.000 (  0.000)recall:   0.000 (  0.000)soec:   0.000 (  0.003)f1:   0.000 (  0.000)
2023-11-30 09:13:51,661 Test: [  10/39]  Time: 0.058 (0.239)  Loss:   0.852 ( 0.852)  Acc@1:   0.000 (  0.284)  Acc@5: 100.000 (100.000)precision:   0.000 (  0.000)recall:   0.000 (  0.000)soec:   0.000 (  0.003)f1:   0.000 (  0.000)
2023-11-30 09:13:52,022 Test: [  11/39]  Time: 0.361 (0.249)  Loss:   0.834 ( 0.850)  Acc@1:   0.000 (  0.260)  Acc@5: 100.000 (100.000)precision:   0.000 (  0.000)recall:   0.000 (  0.000)soec:   0.000 (  0.003)f1:   0.000 (  0.000)
2023-11-30 09:13:52,222 Test: [  12/39]  Time: 0.200 (0.245)  Loss:   0.844 ( 0.850)  Acc@1:   0.000 (  0.240)  Acc@5: 100.000 (100.000)precision:   0.000 (  0.000)recall:   0.000 (  0.000)soec:   0.000 (  0.002)f1:   0.000 (  0.000)
2023-11-30 09:13:52,279 Test: [  13/39]  Time: 0.058 (0.232)  Loss:   0.840 ( 0.849)  Acc@1:   0.000 (  0.223)  Acc@5: 100.000 (100.000)precision:   0.000 (  0.000)recall:   0.000 (  0.000)soec:   0.000 (  0.002)f1:   0.000 (  0.000)
2023-11-30 09:13:52,337 Test: [  14/39]  Time: 0.058 (0.220)  Loss:   0.845 ( 0.849)  Acc@1:   0.000 (  0.208)  Acc@5: 100.000 (100.000)precision:   0.000 (  0.000)recall:   0.000 (  0.000)soec:   0.000 (  0.002)f1:   0.000 (  0.000)
2023-11-30 09:13:52,719 Test: [  15/39]  Time: 0.382 (0.230)  Loss:   0.855 ( 0.849)  Acc@1:   0.000 (  0.195)  Acc@5: 100.000 (100.000)precision:   0.000 (  0.000)recall:   0.000 (  0.000)soec:   0.000 (  0.002)f1:   0.000 (  0.000)
2023-11-30 09:13:52,900 Test: [  16/39]  Time: 0.182 (0.228)  Loss:   0.847 ( 0.849)  Acc@1:   0.000 (  0.184)  Acc@5: 100.000 (100.000)precision:   0.000 (  0.000)recall:   0.000 (  0.000)soec:   0.000 (  0.002)f1:   0.000 (  0.000)
2023-11-30 09:13:52,958 Test: [  17/39]  Time: 0.058 (0.218)  Loss:   0.846 ( 0.849)  Acc@1:   0.000 (  0.174)  Acc@5: 100.000 (100.000)precision:   0.000 (  0.000)recall:   0.000 (  0.000)soec:   0.000 (  0.002)f1:   0.000 (  0.000)
2023-11-30 09:13:53,016 Test: [  18/39]  Time: 0.058 (0.210)  Loss:   0.838 ( 0.848)  Acc@1:   0.000 (  0.164)  Acc@5: 100.000 (100.000)precision:   0.000 (  0.000)recall:   0.000 (  0.000)soec:   0.000 (  0.002)f1:   0.000 (  0.000)
2023-11-30 09:13:53,359 Test: [  19/39]  Time: 0.344 (0.216)  Loss:   0.853 ( 0.849)  Acc@1:   0.000 (  0.156)  Acc@5: 100.000 (100.000)precision:   0.000 (  0.000)recall:   0.000 (  0.000)soec:   0.000 (  0.002)f1:   0.000 (  0.000)
2023-11-30 09:13:53,580 Test: [  20/39]  Time: 0.220 (0.217)  Loss:   0.859 ( 0.849)  Acc@1:   0.000 (  0.149)  Acc@5: 100.000 (100.000)precision:   0.000 (  0.000)recall:   0.000 (  0.000)soec:   0.000 (  0.001)f1:   0.000 (  0.000)
2023-11-30 09:13:53,637 Test: [  21/39]  Time: 0.058 (0.209)  Loss:   0.846 ( 0.849)  Acc@1:   0.000 (  0.142)  Acc@5: 100.000 (100.000)precision:   0.000 (  0.000)recall:   0.000 (  0.000)soec:   0.000 (  0.001)f1:   0.000 (  0.000)
2023-11-30 09:13:53,695 Test: [  22/39]  Time: 0.058 (0.203)  Loss:   0.634 ( 0.840)  Acc@1:  71.875 (  3.261)  Acc@5: 100.000 (100.000)precision:   0.742 (  0.032)recall:   0.958 (  0.042)soec:   0.000 (  0.001)f1:   0.836 (  0.036)
2023-11-30 09:13:54,061 Test: [  23/39]  Time: 0.366 (0.210)  Loss:   0.546 ( 0.827)  Acc@1: 100.000 (  7.292)  Acc@5: 100.000 (100.000)precision:   1.000 (  0.073)recall:   1.000 (  0.082)soec:   0.000 (  0.001)f1:   1.000 (  0.077)
2023-11-30 09:13:54,333 Test: [  24/39]  Time: 0.272 (0.212)  Loss:   0.555 ( 0.816)  Acc@1: 100.000 ( 11.000)  Acc@5: 100.000 (100.000)precision:   1.000 (  0.110)recall:   1.000 (  0.118)soec:   0.000 (  0.001)f1:   1.000 (  0.113)
2023-11-30 09:13:54,391 Test: [  25/39]  Time: 0.058 (0.206)  Loss:   0.547 ( 0.806)  Acc@1: 100.000 ( 14.423)  Acc@5: 100.000 (100.000)precision:   1.000 (  0.144)recall:   1.000 (  0.152)soec:   0.000 (  0.001)f1:   1.000 (  0.148)
2023-11-30 09:13:54,449 Test: [  26/39]  Time: 0.058 (0.201)  Loss:   0.550 ( 0.797)  Acc@1: 100.000 ( 17.593)  Acc@5: 100.000 (100.000)precision:   1.000 (  0.176)recall:   1.000 (  0.184)soec:   0.000 (  0.001)f1:   1.000 (  0.179)
2023-11-30 09:13:54,801 Test: [  27/39]  Time: 0.351 (0.206)  Loss:   0.546 ( 0.788)  Acc@1: 100.000 ( 20.536)  Acc@5: 100.000 (100.000)precision:   1.000 (  0.205)recall:   1.000 (  0.213)soec:   0.000 (  0.001)f1:   1.000 (  0.208)
2023-11-30 09:13:55,024 Test: [  28/39]  Time: 0.224 (0.207)  Loss:   0.552 ( 0.780)  Acc@1: 100.000 ( 23.276)  Acc@5: 100.000 (100.000)precision:   1.000 (  0.232)recall:   1.000 (  0.240)soec:   0.000 (  0.001)f1:   1.000 (  0.236)
2023-11-30 09:13:55,082 Test: [  29/39]  Time: 0.058 (0.202)  Loss:   0.555 ( 0.772)  Acc@1: 100.000 ( 25.833)  Acc@5: 100.000 (100.000)precision:   1.000 (  0.258)recall:   1.000 (  0.265)soec:   0.000 (  0.001)f1:   1.000 (  0.261)
2023-11-30 09:13:55,140 Test: [  30/39]  Time: 0.058 (0.197)  Loss:   0.555 ( 0.765)  Acc@1: 100.000 ( 28.226)  Acc@5: 100.000 (100.000)precision:   1.000 (  0.282)recall:   1.000 (  0.289)soec:   0.000 (  0.001)f1:   1.000 (  0.285)
2023-11-30 09:13:55,467 Test: [  31/39]  Time: 0.328 (0.201)  Loss:   0.552 ( 0.758)  Acc@1: 100.000 ( 30.469)  Acc@5: 100.000 (100.000)precision:   1.000 (  0.304)recall:   1.000 (  0.311)soec:   0.000 (  0.001)f1:   1.000 (  0.307)
2023-11-30 09:13:55,663 Test: [  32/39]  Time: 0.196 (0.201)  Loss:   0.552 ( 0.752)  Acc@1: 100.000 ( 32.576)  Acc@5: 100.000 (100.000)precision:   1.000 (  0.326)recall:   1.000 (  0.332)soec:   0.000 (  0.001)f1:   1.000 (  0.328)
2023-11-30 09:13:55,721 Test: [  33/39]  Time: 0.058 (0.197)  Loss:   0.555 ( 0.746)  Acc@1: 100.000 ( 34.559)  Acc@5: 100.000 (100.000)precision:   1.000 (  0.345)recall:   1.000 (  0.352)soec:   0.000 (  0.001)f1:   1.000 (  0.348)
2023-11-30 09:13:55,778 Test: [  34/39]  Time: 0.058 (0.193)  Loss:   0.546 ( 0.741)  Acc@1: 100.000 ( 36.429)  Acc@5: 100.000 (100.000)precision:   1.000 (  0.364)recall:   1.000 (  0.370)soec:   0.000 (  0.001)f1:   1.000 (  0.367)
2023-11-30 09:13:55,853 Test: [  35/39]  Time: 0.075 (0.189)  Loss:   0.552 ( 0.735)  Acc@1: 100.000 ( 38.194)  Acc@5: 100.000 (100.000)precision:   1.000 (  0.382)recall:   1.000 (  0.388)soec:   0.000 (  0.001)f1:   1.000 (  0.384)
2023-11-30 09:13:56,197 Test: [  36/39]  Time: 0.344 (0.194)  Loss:   0.634 ( 0.733)  Acc@1:  71.875 ( 39.105)  Acc@5: 100.000 (100.000)precision:   1.000 (  0.398)recall:   0.719 (  0.397)soec:   0.000 (  0.001)f1:   0.836 (  0.397)
2023-11-30 09:13:56,846 Test: [  37/39]  Time: 0.649 (0.206)  Loss:   0.607 ( 0.729)  Acc@1:  75.000 ( 40.049)  Acc@5: 100.000 (100.000)precision:   1.000 (  0.414)recall:   0.750 (  0.406)soec:   0.000 (  0.001)f1:   0.857 (  0.409)
2023-11-30 09:13:56,901 Test: [  38/39]  Time: 0.055 (0.202)  Loss:   0.584 ( 0.726)  Acc@1:  90.625 ( 41.346)  Acc@5: 100.000 (100.000)precision:   1.000 (  0.429)recall:   0.906 (  0.419)soec:   0.000 (  0.001)f1:   0.951 (  0.423)
2023-11-30 09:13:57,127 Test: [  39/39]  Time: 0.227 (0.202)  Loss:   0.548 ( 0.725)  Acc@1: 100.000 ( 41.440)  Acc@5: 100.000 (100.000)precision:   1.000 (  0.430)recall:   1.000 (  0.420)soec:   0.000 (  0.001)f1:   1.000 (  0.424)
2023-11-30 09:13:57,335 Current checkpoints:
 ('./output/train/20231130-091337-efficientnet_b0-275/checkpoint-0.pth.tar', 41.44)

2023-11-30 09:13:57,335 *** Best metric: 41.44 (epoch 0)

2023-11-30 09:30:25,833 Training with a single process on 1 device (cuda:0).
2023-11-30 09:30:26,045 Model efficientnet_b0 created, param count:8733680
2023-11-30 09:30:26,045 Data processing configuration for current model + dataset:
2023-11-30 09:30:26,045 	input_size: (3, 259, 259)
2023-11-30 09:30:26,046 	interpolation: bicubic
2023-11-30 09:30:26,046 	mean: (0.485, 0.456, 0.406)
2023-11-30 09:30:26,046 	std: (0.229, 0.224, 0.225)
2023-11-30 09:30:26,046 	crop_pct: 0.875
2023-11-30 09:30:26,046 	crop_mode: center
2023-11-30 09:30:28,447 AMP not enabled. Training in float32.
2023-11-30 09:30:28,490 Scheduled epochs: 1. LR stepped per epoch.
2023-11-30 09:30:30,622 FLOPs: 39.779662336 GFLOPs
2023-11-30 09:30:31,730 Train: 0 [   0/39 (  0%)]  Loss: 1.38 (1.38)  Time: 3.237s,    9.89/s  (3.237s,    9.89/s)  LR: 1.000e-05  Data: 0.980 (0.980)
2023-11-30 09:30:31,993 Train: 0 [   1/39 (  3%)]  Loss: 0.876 (1.13)  Time: 0.263s,  121.53/s  (1.750s,   18.28/s)  LR: 1.000e-05  Data: 0.006 (0.493)
2023-11-30 09:30:32,253 Train: 0 [   2/39 (  5%)]  Loss: 0.998 (1.09)  Time: 0.260s,  122.95/s  (1.254s,   25.53/s)  LR: 1.000e-05  Data: 0.003 (0.329)
2023-11-30 09:30:32,536 Train: 0 [   3/39 (  8%)]  Loss: 0.736 (0.998)  Time: 0.282s,  113.32/s  (1.011s,   31.66/s)  LR: 1.000e-05  Data: 0.025 (0.253)
2023-11-30 09:30:32,799 Train: 0 [   4/39 ( 11%)]  Loss: 0.971 (0.993)  Time: 0.263s,  121.49/s  (0.861s,   37.15/s)  LR: 1.000e-05  Data: 0.006 (0.204)
2023-11-30 09:30:33,060 Train: 0 [   5/39 ( 13%)]  Loss: 1.26 (1.04)  Time: 0.260s,  122.85/s  (0.761s,   42.04/s)  LR: 1.000e-05  Data: 0.003 (0.170)
2023-11-30 09:30:33,320 Train: 0 [   6/39 ( 16%)]  Loss: 1.23 (1.06)  Time: 0.260s,  122.92/s  (0.690s,   46.40/s)  LR: 1.000e-05  Data: 0.003 (0.146)
2023-11-30 09:30:33,582 Train: 0 [   7/39 ( 18%)]  Loss: 0.919 (1.05)  Time: 0.262s,  122.17/s  (0.636s,   50.30/s)  LR: 1.000e-05  Data: 0.005 (0.129)
2023-11-30 09:30:33,844 Train: 0 [   8/39 ( 21%)]  Loss: 1.93 (1.14)  Time: 0.262s,  122.30/s  (0.595s,   53.82/s)  LR: 1.000e-05  Data: 0.004 (0.115)
2023-11-30 09:30:34,106 Train: 0 [   9/39 ( 24%)]  Loss: 1.46 (1.18)  Time: 0.262s,  121.91/s  (0.561s,   57.01/s)  LR: 1.000e-05  Data: 0.005 (0.104)
2023-11-30 09:30:34,369 Train: 0 [  10/39 ( 26%)]  Loss: 1.78 (1.23)  Time: 0.263s,  121.66/s  (0.534s,   59.90/s)  LR: 1.000e-05  Data: 0.005 (0.095)
2023-11-30 09:30:34,632 Train: 0 [  11/39 ( 29%)]  Loss: 1.21 (1.23)  Time: 0.263s,  121.81/s  (0.512s,   62.55/s)  LR: 1.000e-05  Data: 0.005 (0.087)
2023-11-30 09:30:34,894 Train: 0 [  12/39 ( 32%)]  Loss: 1.31 (1.23)  Time: 0.262s,  121.93/s  (0.492s,   64.99/s)  LR: 1.000e-05  Data: 0.005 (0.081)
2023-11-30 09:30:35,156 Train: 0 [  13/39 ( 34%)]  Loss: 1.91 (1.28)  Time: 0.262s,  122.06/s  (0.476s,   67.23/s)  LR: 1.000e-05  Data: 0.004 (0.075)
2023-11-30 09:30:35,419 Train: 0 [  14/39 ( 37%)]  Loss: 1.12 (1.27)  Time: 0.263s,  121.76/s  (0.462s,   69.30/s)  LR: 1.000e-05  Data: 0.005 (0.071)
2023-11-30 09:30:35,683 Train: 0 [  15/39 ( 39%)]  Loss: 1.05 (1.26)  Time: 0.264s,  121.15/s  (0.449s,   71.21/s)  LR: 1.000e-05  Data: 0.005 (0.067)
2023-11-30 09:30:35,948 Train: 0 [  16/39 ( 42%)]  Loss: 2.06 (1.31)  Time: 0.265s,  120.78/s  (0.439s,   72.97/s)  LR: 1.000e-05  Data: 0.005 (0.063)
2023-11-30 09:30:36,212 Train: 0 [  17/39 ( 45%)]  Loss: 0.833 (1.28)  Time: 0.264s,  121.21/s  (0.429s,   74.62/s)  LR: 1.000e-05  Data: 0.005 (0.060)
2023-11-30 09:30:36,476 Train: 0 [  18/39 ( 47%)]  Loss: 0.947 (1.26)  Time: 0.264s,  121.16/s  (0.420s,   76.16/s)  LR: 1.000e-05  Data: 0.005 (0.057)
2023-11-30 09:30:36,741 Train: 0 [  19/39 ( 50%)]  Loss: 1.56 (1.28)  Time: 0.265s,  120.80/s  (0.412s,   77.59/s)  LR: 1.000e-05  Data: 0.005 (0.054)
2023-11-30 09:30:37,004 Train: 0 [  20/39 ( 53%)]  Loss: 0.965 (1.26)  Time: 0.263s,  121.77/s  (0.405s,   78.95/s)  LR: 1.000e-05  Data: 0.005 (0.052)
2023-11-30 09:30:37,266 Train: 0 [  21/39 ( 55%)]  Loss: 1.08 (1.25)  Time: 0.262s,  122.08/s  (0.399s,   80.24/s)  LR: 1.000e-05  Data: 0.004 (0.050)
2023-11-30 09:30:37,528 Train: 0 [  22/39 ( 58%)]  Loss: 1.86 (1.28)  Time: 0.262s,  122.01/s  (0.393s,   81.46/s)  LR: 1.000e-05  Data: 0.005 (0.048)
2023-11-30 09:30:37,791 Train: 0 [  23/39 ( 61%)]  Loss: 0.941 (1.27)  Time: 0.262s,  121.99/s  (0.387s,   82.60/s)  LR: 1.000e-05  Data: 0.004 (0.046)
2023-11-30 09:30:38,053 Train: 0 [  24/39 ( 63%)]  Loss: 1.31 (1.27)  Time: 0.262s,  121.93/s  (0.382s,   83.68/s)  LR: 1.000e-05  Data: 0.004 (0.044)
2023-11-30 09:30:38,315 Train: 0 [  25/39 ( 66%)]  Loss: 1.06 (1.26)  Time: 0.262s,  122.11/s  (0.378s,   84.70/s)  LR: 1.000e-05  Data: 0.004 (0.043)
2023-11-30 09:30:38,578 Train: 0 [  26/39 ( 68%)]  Loss: 0.998 (1.25)  Time: 0.262s,  121.99/s  (0.374s,   85.67/s)  LR: 1.000e-05  Data: 0.005 (0.041)
2023-11-30 09:30:38,840 Train: 0 [  27/39 ( 71%)]  Loss: 0.885 (1.24)  Time: 0.262s,  122.02/s  (0.370s,   86.60/s)  LR: 1.000e-05  Data: 0.005 (0.040)
2023-11-30 09:30:39,102 Train: 0 [  28/39 ( 74%)]  Loss: 1.86 (1.26)  Time: 0.262s,  121.93/s  (0.366s,   87.47/s)  LR: 1.000e-05  Data: 0.005 (0.039)
2023-11-30 09:30:39,365 Train: 0 [  29/39 ( 76%)]  Loss: 0.989 (1.25)  Time: 0.263s,  121.80/s  (0.362s,   88.30/s)  LR: 1.000e-05  Data: 0.004 (0.038)
2023-11-30 09:30:39,627 Train: 0 [  30/39 ( 79%)]  Loss: 1.07 (1.24)  Time: 0.262s,  121.92/s  (0.359s,   89.09/s)  LR: 1.000e-05  Data: 0.004 (0.037)
2023-11-30 09:30:39,889 Train: 0 [  31/39 ( 82%)]  Loss: 1.67 (1.26)  Time: 0.262s,  122.34/s  (0.356s,   89.85/s)  LR: 1.000e-05  Data: 0.004 (0.036)
2023-11-30 09:30:40,150 Train: 0 [  32/39 ( 84%)]  Loss: 1.05 (1.25)  Time: 0.261s,  122.71/s  (0.353s,   90.59/s)  LR: 1.000e-05  Data: 0.004 (0.035)
2023-11-30 09:30:40,410 Train: 0 [  33/39 ( 87%)]  Loss: 1.36 (1.25)  Time: 0.260s,  122.99/s  (0.351s,   91.30/s)  LR: 1.000e-05  Data: 0.004 (0.034)
2023-11-30 09:30:40,671 Train: 0 [  34/39 ( 89%)]  Loss: 0.980 (1.25)  Time: 0.261s,  122.58/s  (0.348s,   91.97/s)  LR: 1.000e-05  Data: 0.004 (0.033)
2023-11-30 09:30:40,932 Train: 0 [  35/39 ( 92%)]  Loss: 1.12 (1.24)  Time: 0.261s,  122.66/s  (0.346s,   92.61/s)  LR: 1.000e-05  Data: 0.004 (0.032)
2023-11-30 09:30:41,193 Train: 0 [  36/39 ( 95%)]  Loss: 1.26 (1.24)  Time: 0.261s,  122.65/s  (0.343s,   93.23/s)  LR: 1.000e-05  Data: 0.004 (0.031)
2023-11-30 09:30:41,454 Train: 0 [  37/39 ( 97%)]  Loss: 1.01 (1.24)  Time: 0.261s,  122.53/s  (0.341s,   93.82/s)  LR: 1.000e-05  Data: 0.004 (0.031)
2023-11-30 09:30:41,711 Train: 0 [  38/39 (100%)]  Loss: 2.57 (1.27)  Time: 0.257s,  124.45/s  (0.339s,   94.41/s)  LR: 1.000e-05  Data: 0.000 (0.030)
2023-11-30 09:30:42,834 Test: [   0/39]  Time: 1.120 (1.120)  Loss:   0.187 ( 0.187)  Acc@1: 100.000 (100.000)  Acc@5: 100.000 (100.000)precision:   0.000 (  0.000)recall:   0.000 (  0.000)soec:   1.000 (  1.000)f1:   0.000 (  0.000)
2023-11-30 09:30:42,899 Test: [   1/39]  Time: 0.064 (0.592)  Loss:   0.184 ( 0.186)  Acc@1: 100.000 (100.000)  Acc@5: 100.000 (100.000)precision:   0.000 (  0.000)recall:   0.000 (  0.000)soec:   1.000 (  1.000)f1:   0.000 (  0.000)
2023-11-30 09:30:42,962 Test: [   2/39]  Time: 0.064 (0.416)  Loss:   0.187 ( 0.186)  Acc@1: 100.000 (100.000)  Acc@5: 100.000 (100.000)precision:   0.000 (  0.000)recall:   0.000 (  0.000)soec:   1.000 (  1.000)f1:   0.000 (  0.000)
2023-11-30 09:30:43,320 Test: [   3/39]  Time: 0.357 (0.401)  Loss:   0.188 ( 0.187)  Acc@1: 100.000 (100.000)  Acc@5: 100.000 (100.000)precision:   0.000 (  0.000)recall:   0.000 (  0.000)soec:   1.000 (  1.000)f1:   0.000 (  0.000)
2023-11-30 09:30:43,498 Test: [   4/39]  Time: 0.178 (0.357)  Loss:   0.188 ( 0.187)  Acc@1: 100.000 (100.000)  Acc@5: 100.000 (100.000)precision:   0.000 (  0.000)recall:   0.000 (  0.000)soec:   1.000 (  1.000)f1:   0.000 (  0.000)
2023-11-30 09:30:43,562 Test: [   5/39]  Time: 0.064 (0.308)  Loss:   0.192 ( 0.188)  Acc@1: 100.000 (100.000)  Acc@5: 100.000 (100.000)precision:   0.000 (  0.000)recall:   0.000 (  0.000)soec:   1.000 (  1.000)f1:   0.000 (  0.000)
2023-11-30 09:30:43,625 Test: [   6/39]  Time: 0.064 (0.273)  Loss:   0.187 ( 0.188)  Acc@1: 100.000 (100.000)  Acc@5: 100.000 (100.000)precision:   0.000 (  0.000)recall:   0.000 (  0.000)soec:   1.000 (  1.000)f1:   0.000 (  0.000)
2023-11-30 09:30:43,966 Test: [   7/39]  Time: 0.341 (0.281)  Loss:   0.186 ( 0.187)  Acc@1: 100.000 (100.000)  Acc@5: 100.000 (100.000)precision:   0.000 (  0.000)recall:   0.000 (  0.000)soec:   1.000 (  1.000)f1:   0.000 (  0.000)
2023-11-30 09:30:44,182 Test: [   8/39]  Time: 0.216 (0.274)  Loss:   0.186 ( 0.187)  Acc@1: 100.000 (100.000)  Acc@5: 100.000 (100.000)precision:   0.000 (  0.000)recall:   0.000 (  0.000)soec:   1.000 (  1.000)f1:   0.000 (  0.000)
2023-11-30 09:30:44,246 Test: [   9/39]  Time: 0.064 (0.253)  Loss:   0.188 ( 0.187)  Acc@1: 100.000 (100.000)  Acc@5: 100.000 (100.000)precision:   0.000 (  0.000)recall:   0.000 (  0.000)soec:   1.000 (  1.000)f1:   0.000 (  0.000)
2023-11-30 09:30:44,310 Test: [  10/39]  Time: 0.064 (0.236)  Loss:   0.188 ( 0.187)  Acc@1: 100.000 (100.000)  Acc@5: 100.000 (100.000)precision:   0.000 (  0.000)recall:   0.000 (  0.000)soec:   1.000 (  1.000)f1:   0.000 (  0.000)
2023-11-30 09:30:44,667 Test: [  11/39]  Time: 0.357 (0.246)  Loss:   0.186 ( 0.187)  Acc@1: 100.000 (100.000)  Acc@5: 100.000 (100.000)precision:   0.000 (  0.000)recall:   0.000 (  0.000)soec:   1.000 (  1.000)f1:   0.000 (  0.000)
2023-11-30 09:30:44,873 Test: [  12/39]  Time: 0.206 (0.243)  Loss:   0.187 ( 0.187)  Acc@1: 100.000 (100.000)  Acc@5: 100.000 (100.000)precision:   0.000 (  0.000)recall:   0.000 (  0.000)soec:   1.000 (  1.000)f1:   0.000 (  0.000)
2023-11-30 09:30:44,938 Test: [  13/39]  Time: 0.065 (0.230)  Loss:   0.187 ( 0.187)  Acc@1: 100.000 (100.000)  Acc@5: 100.000 (100.000)precision:   0.000 (  0.000)recall:   0.000 (  0.000)soec:   1.000 (  1.000)f1:   0.000 (  0.000)
2023-11-30 09:30:45,002 Test: [  14/39]  Time: 0.064 (0.219)  Loss:   0.188 ( 0.187)  Acc@1: 100.000 (100.000)  Acc@5: 100.000 (100.000)precision:   0.000 (  0.000)recall:   0.000 (  0.000)soec:   1.000 (  1.000)f1:   0.000 (  0.000)
2023-11-30 09:30:45,330 Test: [  15/39]  Time: 0.328 (0.226)  Loss:   0.188 ( 0.187)  Acc@1: 100.000 (100.000)  Acc@5: 100.000 (100.000)precision:   0.000 (  0.000)recall:   0.000 (  0.000)soec:   1.000 (  1.000)f1:   0.000 (  0.000)
2023-11-30 09:30:45,536 Test: [  16/39]  Time: 0.206 (0.225)  Loss:   0.187 ( 0.187)  Acc@1: 100.000 (100.000)  Acc@5: 100.000 (100.000)precision:   0.000 (  0.000)recall:   0.000 (  0.000)soec:   1.000 (  1.000)f1:   0.000 (  0.000)
2023-11-30 09:30:45,600 Test: [  17/39]  Time: 0.064 (0.216)  Loss:   0.184 ( 0.187)  Acc@1: 100.000 (100.000)  Acc@5: 100.000 (100.000)precision:   0.000 (  0.000)recall:   0.000 (  0.000)soec:   1.000 (  1.000)f1:   0.000 (  0.000)
2023-11-30 09:30:45,664 Test: [  18/39]  Time: 0.064 (0.208)  Loss:   0.187 ( 0.187)  Acc@1: 100.000 (100.000)  Acc@5: 100.000 (100.000)precision:   0.000 (  0.000)recall:   0.000 (  0.000)soec:   1.000 (  1.000)f1:   0.000 (  0.000)
2023-11-30 09:30:45,952 Test: [  19/39]  Time: 0.288 (0.212)  Loss:   0.185 ( 0.187)  Acc@1: 100.000 (100.000)  Acc@5: 100.000 (100.000)precision:   0.000 (  0.000)recall:   0.000 (  0.000)soec:   1.000 (  1.000)f1:   0.000 (  0.000)
2023-11-30 09:30:46,170 Test: [  20/39]  Time: 0.218 (0.212)  Loss:   0.186 ( 0.187)  Acc@1: 100.000 (100.000)  Acc@5: 100.000 (100.000)precision:   0.000 (  0.000)recall:   0.000 (  0.000)soec:   1.000 (  1.000)f1:   0.000 (  0.000)
2023-11-30 09:30:46,234 Test: [  21/39]  Time: 0.064 (0.205)  Loss:   0.184 ( 0.187)  Acc@1: 100.000 (100.000)  Acc@5: 100.000 (100.000)precision:   0.000 (  0.000)recall:   0.000 (  0.000)soec:   1.000 (  1.000)f1:   0.000 (  0.000)
2023-11-30 09:30:46,298 Test: [  22/39]  Time: 0.064 (0.199)  Loss:   1.353 ( 0.238)  Acc@1:  25.000 ( 96.739)  Acc@5: 100.000 (100.000)precision:   0.000 (  0.000)recall:   0.000 (  0.000)soec:   1.000 (  1.000)f1:   0.000 (  0.000)
2023-11-30 09:30:46,532 Test: [  23/39]  Time: 0.234 (0.201)  Loss:   1.761 ( 0.301)  Acc@1:   0.000 ( 92.708)  Acc@5: 100.000 (100.000)precision:   0.000 (  0.000)recall:   0.000 (  0.000)soec:   0.000 (  0.958)f1:   0.000 (  0.000)
2023-11-30 09:30:46,806 Test: [  24/39]  Time: 0.274 (0.204)  Loss:   1.759 ( 0.359)  Acc@1:   0.000 ( 89.000)  Acc@5: 100.000 (100.000)precision:   0.000 (  0.000)recall:   0.000 (  0.000)soec:   0.000 (  0.920)f1:   0.000 (  0.000)
2023-11-30 09:30:46,870 Test: [  25/39]  Time: 0.064 (0.198)  Loss:   1.769 ( 0.414)  Acc@1:   0.000 ( 85.577)  Acc@5: 100.000 (100.000)precision:   0.000 (  0.000)recall:   0.000 (  0.000)soec:   0.000 (  0.885)f1:   0.000 (  0.000)
2023-11-30 09:30:46,934 Test: [  26/39]  Time: 0.064 (0.193)  Loss:   1.761 ( 0.464)  Acc@1:   0.000 ( 82.407)  Acc@5: 100.000 (100.000)precision:   0.000 (  0.000)recall:   0.000 (  0.000)soec:   0.000 (  0.852)f1:   0.000 (  0.000)
2023-11-30 09:30:47,151 Test: [  27/39]  Time: 0.217 (0.194)  Loss:   1.768 ( 0.510)  Acc@1:   0.000 ( 79.464)  Acc@5: 100.000 (100.000)precision:   0.000 (  0.000)recall:   0.000 (  0.000)soec:   0.000 (  0.821)f1:   0.000 (  0.000)
2023-11-30 09:30:47,390 Test: [  28/39]  Time: 0.239 (0.196)  Loss:   1.773 ( 0.554)  Acc@1:   0.000 ( 76.724)  Acc@5: 100.000 (100.000)precision:   0.000 (  0.000)recall:   0.000 (  0.000)soec:   0.000 (  0.793)f1:   0.000 (  0.000)
2023-11-30 09:30:47,454 Test: [  29/39]  Time: 0.064 (0.191)  Loss:   1.774 ( 0.594)  Acc@1:   0.000 ( 74.167)  Acc@5: 100.000 (100.000)precision:   0.000 (  0.000)recall:   0.000 (  0.000)soec:   0.000 (  0.767)f1:   0.000 (  0.000)
2023-11-30 09:30:47,518 Test: [  30/39]  Time: 0.064 (0.187)  Loss:   1.768 ( 0.632)  Acc@1:   0.000 ( 71.774)  Acc@5: 100.000 (100.000)precision:   0.000 (  0.000)recall:   0.000 (  0.000)soec:   0.000 (  0.742)f1:   0.000 (  0.000)
2023-11-30 09:30:47,768 Test: [  31/39]  Time: 0.251 (0.189)  Loss:   1.776 ( 0.668)  Acc@1:   0.000 ( 69.531)  Acc@5: 100.000 (100.000)precision:   0.000 (  0.000)recall:   0.000 (  0.000)soec:   0.000 (  0.719)f1:   0.000 (  0.000)
2023-11-30 09:30:48,006 Test: [  32/39]  Time: 0.237 (0.191)  Loss:   1.759 ( 0.701)  Acc@1:   0.000 ( 67.424)  Acc@5: 100.000 (100.000)precision:   0.000 (  0.000)recall:   0.000 (  0.000)soec:   0.000 (  0.697)f1:   0.000 (  0.000)
2023-11-30 09:30:48,069 Test: [  33/39]  Time: 0.064 (0.187)  Loss:   1.768 ( 0.732)  Acc@1:   0.000 ( 65.441)  Acc@5: 100.000 (100.000)precision:   0.000 (  0.000)recall:   0.000 (  0.000)soec:   0.000 (  0.676)f1:   0.000 (  0.000)
2023-11-30 09:30:48,133 Test: [  34/39]  Time: 0.064 (0.183)  Loss:   1.761 ( 0.762)  Acc@1:   0.000 ( 63.571)  Acc@5: 100.000 (100.000)precision:   0.000 (  0.000)recall:   0.000 (  0.000)soec:   0.000 (  0.657)f1:   0.000 (  0.000)
2023-11-30 09:30:48,199 Test: [  35/39]  Time: 0.066 (0.180)  Loss:   1.773 ( 0.790)  Acc@1:   0.000 ( 61.806)  Acc@5: 100.000 (100.000)precision:   0.000 (  0.000)recall:   0.000 (  0.000)soec:   0.000 (  0.639)f1:   0.000 (  0.000)
2023-11-30 09:30:48,526 Test: [  36/39]  Time: 0.327 (0.184)  Loss:   1.724 ( 0.815)  Acc@1:   0.000 ( 60.135)  Acc@5: 100.000 (100.000)precision:   0.000 (  0.000)recall:   0.000 (  0.000)soec:   0.000 (  0.622)f1:   0.000 (  0.000)
2023-11-30 09:30:49,209 Test: [  37/39]  Time: 0.683 (0.197)  Loss:   1.499 ( 0.833)  Acc@1:   6.250 ( 58.717)  Acc@5: 100.000 (100.000)precision:   1.000 (  0.026)recall:   0.062 (  0.002)soec:   0.000 (  0.605)f1:   0.118 (  0.003)
2023-11-30 09:30:49,270 Test: [  38/39]  Time: 0.061 (0.194)  Loss:   1.559 ( 0.852)  Acc@1:   3.125 ( 57.292)  Acc@5: 100.000 (100.000)precision:   1.000 (  0.051)recall:   0.031 (  0.002)soec:   0.000 (  0.590)f1:   0.061 (  0.005)
2023-11-30 09:30:49,471 Test: [  39/39]  Time: 0.201 (0.194)  Loss:   1.323 ( 0.852)  Acc@1:   0.000 ( 57.200)  Acc@5: 100.000 (100.000)precision:   0.000 (  0.051)recall:   0.000 (  0.002)soec:   0.000 (  0.589)f1:   0.000 (  0.005)
2023-11-30 09:30:49,682 Current checkpoints:
 ('./output/train/20231130-093028-efficientnet_b0-259/checkpoint-0.pth.tar', 57.2)

2023-11-30 09:30:49,682 *** Best metric: 57.2 (epoch 0)

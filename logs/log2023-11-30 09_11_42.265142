2023-11-30 09:11:42,317 Training with a single process on 1 device (cuda:0).
2023-11-30 09:11:42,535 Model efficientnet_b0 created, param count:8733680
2023-11-30 09:11:42,535 Data processing configuration for current model + dataset:
2023-11-30 09:11:42,535 	input_size: (3, 259, 259)
2023-11-30 09:11:42,535 	interpolation: bicubic
2023-11-30 09:11:42,535 	mean: (0.485, 0.456, 0.406)
2023-11-30 09:11:42,535 	std: (0.229, 0.224, 0.225)
2023-11-30 09:11:42,535 	crop_pct: 0.875
2023-11-30 09:11:42,536 	crop_mode: center
2023-11-30 09:11:45,001 AMP not enabled. Training in float32.
2023-11-30 09:11:45,045 Scheduled epochs: 1. LR stepped per epoch.
2023-11-30 09:11:47,232 FLOPs: 39.779662336 GFLOPs
2023-11-30 09:11:48,334 Train: 0 [   0/39 (  0%)]  Loss: 1.38 (1.38)  Time: 3.286s,    9.74/s  (3.286s,    9.74/s)  LR: 1.000e-05  Data: 1.028 (1.028)
2023-11-30 09:11:48,597 Train: 0 [   1/39 (  3%)]  Loss: 0.876 (1.13)  Time: 0.264s,  121.25/s  (1.775s,   18.03/s)  LR: 1.000e-05  Data: 0.007 (0.517)
2023-11-30 09:11:48,858 Train: 0 [   2/39 (  5%)]  Loss: 0.998 (1.09)  Time: 0.260s,  122.91/s  (1.270s,   25.19/s)  LR: 1.000e-05  Data: 0.003 (0.346)
2023-11-30 09:11:49,121 Train: 0 [   3/39 (  8%)]  Loss: 0.736 (0.998)  Time: 0.263s,  121.58/s  (1.018s,   31.42/s)  LR: 1.000e-05  Data: 0.004 (0.260)
2023-11-30 09:11:49,386 Train: 0 [   4/39 ( 11%)]  Loss: 0.971 (0.993)  Time: 0.265s,  120.93/s  (0.868s,   36.88/s)  LR: 1.000e-05  Data: 0.007 (0.210)
2023-11-30 09:11:49,650 Train: 0 [   5/39 ( 13%)]  Loss: 1.26 (1.04)  Time: 0.265s,  120.96/s  (0.767s,   41.71/s)  LR: 1.000e-05  Data: 0.004 (0.175)
2023-11-30 09:11:49,911 Train: 0 [   6/39 ( 16%)]  Loss: 1.23 (1.06)  Time: 0.261s,  122.74/s  (0.695s,   46.06/s)  LR: 1.000e-05  Data: 0.003 (0.151)
2023-11-30 09:11:50,174 Train: 0 [   7/39 ( 18%)]  Loss: 0.919 (1.05)  Time: 0.264s,  121.39/s  (0.641s,   49.93/s)  LR: 1.000e-05  Data: 0.004 (0.132)
2023-11-30 09:11:50,438 Train: 0 [   8/39 ( 21%)]  Loss: 1.93 (1.14)  Time: 0.263s,  121.59/s  (0.599s,   53.43/s)  LR: 1.000e-05  Data: 0.005 (0.118)
2023-11-30 09:11:50,701 Train: 0 [   9/39 ( 24%)]  Loss: 1.46 (1.18)  Time: 0.263s,  121.52/s  (0.565s,   56.60/s)  LR: 1.000e-05  Data: 0.005 (0.107)
2023-11-30 09:11:50,965 Train: 0 [  10/39 ( 26%)]  Loss: 1.78 (1.23)  Time: 0.264s,  121.15/s  (0.538s,   59.48/s)  LR: 1.000e-05  Data: 0.005 (0.098)
2023-11-30 09:11:51,228 Train: 0 [  11/39 ( 29%)]  Loss: 1.21 (1.23)  Time: 0.263s,  121.85/s  (0.515s,   62.13/s)  LR: 1.000e-05  Data: 0.004 (0.090)
2023-11-30 09:11:51,490 Train: 0 [  12/39 ( 32%)]  Loss: 1.31 (1.23)  Time: 0.262s,  122.03/s  (0.496s,   64.57/s)  LR: 1.000e-05  Data: 0.004 (0.083)
2023-11-30 09:11:51,752 Train: 0 [  13/39 ( 34%)]  Loss: 1.91 (1.28)  Time: 0.262s,  122.09/s  (0.479s,   66.82/s)  LR: 1.000e-05  Data: 0.004 (0.078)
2023-11-30 09:11:52,014 Train: 0 [  14/39 ( 37%)]  Loss: 1.12 (1.27)  Time: 0.262s,  122.20/s  (0.464s,   68.90/s)  LR: 1.000e-05  Data: 0.004 (0.073)
2023-11-30 09:11:52,276 Train: 0 [  15/39 ( 39%)]  Loss: 1.05 (1.26)  Time: 0.262s,  122.01/s  (0.452s,   70.83/s)  LR: 1.000e-05  Data: 0.004 (0.069)
2023-11-30 09:11:52,540 Train: 0 [  16/39 ( 42%)]  Loss: 2.06 (1.31)  Time: 0.264s,  121.37/s  (0.441s,   72.61/s)  LR: 1.000e-05  Data: 0.004 (0.065)
2023-11-30 09:11:52,803 Train: 0 [  17/39 ( 45%)]  Loss: 0.833 (1.28)  Time: 0.263s,  121.68/s  (0.431s,   74.27/s)  LR: 1.000e-05  Data: 0.005 (0.061)
2023-11-30 09:11:53,065 Train: 0 [  18/39 ( 47%)]  Loss: 0.948 (1.26)  Time: 0.262s,  122.05/s  (0.422s,   75.83/s)  LR: 1.000e-05  Data: 0.004 (0.058)
2023-11-30 09:11:53,327 Train: 0 [  19/39 ( 50%)]  Loss: 1.56 (1.28)  Time: 0.262s,  121.96/s  (0.414s,   77.29/s)  LR: 1.000e-05  Data: 0.004 (0.056)
2023-11-30 09:11:53,590 Train: 0 [  20/39 ( 53%)]  Loss: 0.965 (1.26)  Time: 0.262s,  122.03/s  (0.407s,   78.67/s)  LR: 1.000e-05  Data: 0.004 (0.053)
2023-11-30 09:11:53,852 Train: 0 [  21/39 ( 55%)]  Loss: 1.08 (1.25)  Time: 0.263s,  121.89/s  (0.400s,   79.96/s)  LR: 1.000e-05  Data: 0.005 (0.051)
2023-11-30 09:11:54,115 Train: 0 [  22/39 ( 58%)]  Loss: 1.86 (1.28)  Time: 0.263s,  121.87/s  (0.394s,   81.17/s)  LR: 1.000e-05  Data: 0.004 (0.049)
2023-11-30 09:11:54,377 Train: 0 [  23/39 ( 61%)]  Loss: 0.942 (1.27)  Time: 0.262s,  122.06/s  (0.389s,   82.32/s)  LR: 1.000e-05  Data: 0.004 (0.047)
2023-11-30 09:11:54,639 Train: 0 [  24/39 ( 63%)]  Loss: 1.31 (1.27)  Time: 0.262s,  122.08/s  (0.384s,   83.41/s)  LR: 1.000e-05  Data: 0.004 (0.045)
2023-11-30 09:11:54,901 Train: 0 [  25/39 ( 66%)]  Loss: 1.06 (1.26)  Time: 0.262s,  122.20/s  (0.379s,   84.44/s)  LR: 1.000e-05  Data: 0.004 (0.044)
2023-11-30 09:11:55,163 Train: 0 [  26/39 ( 68%)]  Loss: 1.00 (1.25)  Time: 0.262s,  121.92/s  (0.375s,   85.41/s)  LR: 1.000e-05  Data: 0.005 (0.042)
2023-11-30 09:11:55,426 Train: 0 [  27/39 ( 71%)]  Loss: 0.885 (1.24)  Time: 0.262s,  121.96/s  (0.371s,   86.33/s)  LR: 1.000e-05  Data: 0.005 (0.041)
2023-11-30 09:11:55,690 Train: 0 [  28/39 ( 74%)]  Loss: 1.86 (1.26)  Time: 0.264s,  121.14/s  (0.367s,   87.20/s)  LR: 1.000e-05  Data: 0.004 (0.040)
2023-11-30 09:11:55,952 Train: 0 [  29/39 ( 76%)]  Loss: 0.990 (1.25)  Time: 0.262s,  122.02/s  (0.363s,   88.03/s)  LR: 1.000e-05  Data: 0.005 (0.039)
2023-11-30 09:11:56,214 Train: 0 [  30/39 ( 79%)]  Loss: 1.07 (1.24)  Time: 0.262s,  122.22/s  (0.360s,   88.84/s)  LR: 1.000e-05  Data: 0.004 (0.038)
2023-11-30 09:11:56,475 Train: 0 [  31/39 ( 82%)]  Loss: 1.67 (1.26)  Time: 0.261s,  122.63/s  (0.357s,   89.61/s)  LR: 1.000e-05  Data: 0.004 (0.036)
2023-11-30 09:11:56,736 Train: 0 [  32/39 ( 84%)]  Loss: 1.06 (1.25)  Time: 0.261s,  122.72/s  (0.354s,   90.35/s)  LR: 1.000e-05  Data: 0.004 (0.036)
2023-11-30 09:11:56,997 Train: 0 [  33/39 ( 87%)]  Loss: 1.35 (1.25)  Time: 0.261s,  122.42/s  (0.351s,   91.05/s)  LR: 1.000e-05  Data: 0.004 (0.035)
2023-11-30 09:11:57,258 Train: 0 [  34/39 ( 89%)]  Loss: 0.989 (1.25)  Time: 0.261s,  122.72/s  (0.349s,   91.72/s)  LR: 1.000e-05  Data: 0.004 (0.034)
2023-11-30 09:11:57,518 Train: 0 [  35/39 ( 92%)]  Loss: 1.16 (1.24)  Time: 0.260s,  122.95/s  (0.346s,   92.38/s)  LR: 1.000e-05  Data: 0.004 (0.033)
2023-11-30 09:11:57,779 Train: 0 [  36/39 ( 95%)]  Loss: 1.31 (1.25)  Time: 0.261s,  122.63/s  (0.344s,   93.00/s)  LR: 1.000e-05  Data: 0.004 (0.032)
2023-11-30 09:11:58,039 Train: 0 [  37/39 ( 97%)]  Loss: 1.01 (1.24)  Time: 0.260s,  122.93/s  (0.342s,   93.60/s)  LR: 1.000e-05  Data: 0.004 (0.031)
2023-11-30 09:11:58,296 Train: 0 [  38/39 (100%)]  Loss: 2.52 (1.27)  Time: 0.256s,  124.85/s  (0.340s,   94.20/s)  LR: 1.000e-05  Data: 0.000 (0.031)
2023-11-30 09:11:59,434 Test: [   0/39]  Time: 1.135 (1.135)  Loss:   0.200 ( 0.200)  Acc@1: 100.000 (100.000)  Acc@5: 100.000 (100.000)precision:   0.000 (  0.000)recall:   0.000 (  0.000)soec:   1.000 (  1.000)f1:   0.000 (  0.000)
2023-11-30 09:11:59,498 Test: [   1/39]  Time: 0.064 (0.600)  Loss:   0.197 ( 0.199)  Acc@1: 100.000 (100.000)  Acc@5: 100.000 (100.000)precision:   0.000 (  0.000)recall:   0.000 (  0.000)soec:   1.000 (  1.000)f1:   0.000 (  0.000)
2023-11-30 09:11:59,562 Test: [   2/39]  Time: 0.064 (0.421)  Loss:   0.200 ( 0.199)  Acc@1: 100.000 (100.000)  Acc@5: 100.000 (100.000)precision:   0.000 (  0.000)recall:   0.000 (  0.000)soec:   1.000 (  1.000)f1:   0.000 (  0.000)
2023-11-30 09:11:59,932 Test: [   3/39]  Time: 0.371 (0.408)  Loss:   0.201 ( 0.200)  Acc@1: 100.000 (100.000)  Acc@5: 100.000 (100.000)precision:   0.000 (  0.000)recall:   0.000 (  0.000)soec:   1.000 (  1.000)f1:   0.000 (  0.000)
2023-11-30 09:12:00,079 Test: [   4/39]  Time: 0.147 (0.356)  Loss:   0.201 ( 0.200)  Acc@1: 100.000 (100.000)  Acc@5: 100.000 (100.000)precision:   0.000 (  0.000)recall:   0.000 (  0.000)soec:   1.000 (  1.000)f1:   0.000 (  0.000)
2023-11-30 09:12:00,143 Test: [   5/39]  Time: 0.064 (0.307)  Loss:   0.205 ( 0.201)  Acc@1: 100.000 (100.000)  Acc@5: 100.000 (100.000)precision:   0.000 (  0.000)recall:   0.000 (  0.000)soec:   1.000 (  1.000)f1:   0.000 (  0.000)
2023-11-30 09:12:00,207 Test: [   6/39]  Time: 0.064 (0.273)  Loss:   0.200 ( 0.201)  Acc@1: 100.000 (100.000)  Acc@5: 100.000 (100.000)precision:   0.000 (  0.000)recall:   0.000 (  0.000)soec:   1.000 (  1.000)f1:   0.000 (  0.000)
2023-11-30 09:12:00,522 Test: [   7/39]  Time: 0.315 (0.278)  Loss:   0.199 ( 0.200)  Acc@1: 100.000 (100.000)  Acc@5: 100.000 (100.000)precision:   0.000 (  0.000)recall:   0.000 (  0.000)soec:   1.000 (  1.000)f1:   0.000 (  0.000)
2023-11-30 09:12:00,756 Test: [   8/39]  Time: 0.234 (0.273)  Loss:   0.199 ( 0.200)  Acc@1: 100.000 (100.000)  Acc@5: 100.000 (100.000)precision:   0.000 (  0.000)recall:   0.000 (  0.000)soec:   1.000 (  1.000)f1:   0.000 (  0.000)
2023-11-30 09:12:00,820 Test: [   9/39]  Time: 0.064 (0.252)  Loss:   0.201 ( 0.200)  Acc@1: 100.000 (100.000)  Acc@5: 100.000 (100.000)precision:   0.000 (  0.000)recall:   0.000 (  0.000)soec:   1.000 (  1.000)f1:   0.000 (  0.000)
2023-11-30 09:12:00,884 Test: [  10/39]  Time: 0.064 (0.235)  Loss:   0.201 ( 0.200)  Acc@1: 100.000 (100.000)  Acc@5: 100.000 (100.000)precision:   0.000 (  0.000)recall:   0.000 (  0.000)soec:   1.000 (  1.000)f1:   0.000 (  0.000)
2023-11-30 09:12:01,178 Test: [  11/39]  Time: 0.294 (0.240)  Loss:   0.199 ( 0.200)  Acc@1: 100.000 (100.000)  Acc@5: 100.000 (100.000)precision:   0.000 (  0.000)recall:   0.000 (  0.000)soec:   1.000 (  1.000)f1:   0.000 (  0.000)
2023-11-30 09:12:01,419 Test: [  12/39]  Time: 0.241 (0.240)  Loss:   0.200 ( 0.200)  Acc@1: 100.000 (100.000)  Acc@5: 100.000 (100.000)precision:   0.000 (  0.000)recall:   0.000 (  0.000)soec:   1.000 (  1.000)f1:   0.000 (  0.000)
2023-11-30 09:12:01,483 Test: [  13/39]  Time: 0.064 (0.227)  Loss:   0.200 ( 0.200)  Acc@1: 100.000 (100.000)  Acc@5: 100.000 (100.000)precision:   0.000 (  0.000)recall:   0.000 (  0.000)soec:   1.000 (  1.000)f1:   0.000 (  0.000)
2023-11-30 09:12:01,546 Test: [  14/39]  Time: 0.064 (0.216)  Loss:   0.201 ( 0.200)  Acc@1: 100.000 (100.000)  Acc@5: 100.000 (100.000)precision:   0.000 (  0.000)recall:   0.000 (  0.000)soec:   1.000 (  1.000)f1:   0.000 (  0.000)
2023-11-30 09:12:01,852 Test: [  15/39]  Time: 0.306 (0.222)  Loss:   0.201 ( 0.200)  Acc@1: 100.000 (100.000)  Acc@5: 100.000 (100.000)precision:   0.000 (  0.000)recall:   0.000 (  0.000)soec:   1.000 (  1.000)f1:   0.000 (  0.000)
2023-11-30 09:12:02,078 Test: [  16/39]  Time: 0.225 (0.222)  Loss:   0.200 ( 0.200)  Acc@1: 100.000 (100.000)  Acc@5: 100.000 (100.000)precision:   0.000 (  0.000)recall:   0.000 (  0.000)soec:   1.000 (  1.000)f1:   0.000 (  0.000)
2023-11-30 09:12:02,142 Test: [  17/39]  Time: 0.064 (0.213)  Loss:   0.197 ( 0.200)  Acc@1: 100.000 (100.000)  Acc@5: 100.000 (100.000)precision:   0.000 (  0.000)recall:   0.000 (  0.000)soec:   1.000 (  1.000)f1:   0.000 (  0.000)
2023-11-30 09:12:02,205 Test: [  18/39]  Time: 0.064 (0.206)  Loss:   0.200 ( 0.200)  Acc@1: 100.000 (100.000)  Acc@5: 100.000 (100.000)precision:   0.000 (  0.000)recall:   0.000 (  0.000)soec:   1.000 (  1.000)f1:   0.000 (  0.000)
2023-11-30 09:12:02,471 Test: [  19/39]  Time: 0.266 (0.209)  Loss:   0.198 ( 0.200)  Acc@1: 100.000 (100.000)  Acc@5: 100.000 (100.000)precision:   0.000 (  0.000)recall:   0.000 (  0.000)soec:   1.000 (  1.000)f1:   0.000 (  0.000)
2023-11-30 09:12:02,711 Test: [  20/39]  Time: 0.240 (0.210)  Loss:   0.199 ( 0.200)  Acc@1: 100.000 (100.000)  Acc@5: 100.000 (100.000)precision:   0.000 (  0.000)recall:   0.000 (  0.000)soec:   1.000 (  1.000)f1:   0.000 (  0.000)
2023-11-30 09:12:02,775 Test: [  21/39]  Time: 0.064 (0.203)  Loss:   0.197 ( 0.200)  Acc@1: 100.000 (100.000)  Acc@5: 100.000 (100.000)precision:   0.000 (  0.000)recall:   0.000 (  0.000)soec:   1.000 (  1.000)f1:   0.000 (  0.000)
2023-11-30 09:12:02,839 Test: [  22/39]  Time: 0.064 (0.197)  Loss:   1.312 ( 0.248)  Acc@1:  25.000 ( 96.739)  Acc@5: 100.000 (100.000)precision:   0.000 (  0.000)recall:   0.000 (  0.000)soec:   1.000 (  1.000)f1:   0.000 (  0.000)
2023-11-30 09:12:03,060 Test: [  23/39]  Time: 0.222 (0.198)  Loss:   1.700 ( 0.309)  Acc@1:   0.000 ( 92.708)  Acc@5: 100.000 (100.000)precision:   0.000 (  0.000)recall:   0.000 (  0.000)soec:   0.000 (  0.958)f1:   0.000 (  0.000)
2023-11-30 09:12:03,339 Test: [  24/39]  Time: 0.279 (0.202)  Loss:   1.699 ( 0.364)  Acc@1:   0.000 ( 89.000)  Acc@5: 100.000 (100.000)precision:   0.000 (  0.000)recall:   0.000 (  0.000)soec:   0.000 (  0.920)f1:   0.000 (  0.000)
2023-11-30 09:12:03,403 Test: [  25/39]  Time: 0.064 (0.196)  Loss:   1.708 ( 0.416)  Acc@1:   0.000 ( 85.577)  Acc@5: 100.000 (100.000)precision:   0.000 (  0.000)recall:   0.000 (  0.000)soec:   0.000 (  0.885)f1:   0.000 (  0.000)
2023-11-30 09:12:03,466 Test: [  26/39]  Time: 0.064 (0.191)  Loss:   1.701 ( 0.464)  Acc@1:   0.000 ( 82.407)  Acc@5: 100.000 (100.000)precision:   0.000 (  0.000)recall:   0.000 (  0.000)soec:   0.000 (  0.852)f1:   0.000 (  0.000)
2023-11-30 09:12:03,686 Test: [  27/39]  Time: 0.219 (0.192)  Loss:   1.708 ( 0.508)  Acc@1:   0.000 ( 79.464)  Acc@5: 100.000 (100.000)precision:   0.000 (  0.000)recall:   0.000 (  0.000)soec:   0.000 (  0.821)f1:   0.000 (  0.000)
2023-11-30 09:12:03,928 Test: [  28/39]  Time: 0.242 (0.194)  Loss:   1.713 ( 0.550)  Acc@1:   0.000 ( 76.724)  Acc@5: 100.000 (100.000)precision:   0.000 (  0.000)recall:   0.000 (  0.000)soec:   0.000 (  0.793)f1:   0.000 (  0.000)
2023-11-30 09:12:03,992 Test: [  29/39]  Time: 0.064 (0.190)  Loss:   1.713 ( 0.588)  Acc@1:   0.000 ( 74.167)  Acc@5: 100.000 (100.000)precision:   0.000 (  0.000)recall:   0.000 (  0.000)soec:   0.000 (  0.767)f1:   0.000 (  0.000)
2023-11-30 09:12:04,055 Test: [  30/39]  Time: 0.064 (0.186)  Loss:   1.708 ( 0.624)  Acc@1:   0.000 ( 71.774)  Acc@5: 100.000 (100.000)precision:   0.000 (  0.000)recall:   0.000 (  0.000)soec:   0.000 (  0.742)f1:   0.000 (  0.000)
2023-11-30 09:12:04,312 Test: [  31/39]  Time: 0.256 (0.188)  Loss:   1.716 ( 0.659)  Acc@1:   0.000 ( 69.531)  Acc@5: 100.000 (100.000)precision:   0.000 (  0.000)recall:   0.000 (  0.000)soec:   0.000 (  0.719)f1:   0.000 (  0.000)
2023-11-30 09:12:04,533 Test: [  32/39]  Time: 0.221 (0.189)  Loss:   1.698 ( 0.690)  Acc@1:   0.000 ( 67.424)  Acc@5: 100.000 (100.000)precision:   0.000 (  0.000)recall:   0.000 (  0.000)soec:   0.000 (  0.697)f1:   0.000 (  0.000)
2023-11-30 09:12:04,596 Test: [  33/39]  Time: 0.064 (0.185)  Loss:   1.707 ( 0.720)  Acc@1:   0.000 ( 65.441)  Acc@5: 100.000 (100.000)precision:   0.000 (  0.000)recall:   0.000 (  0.000)soec:   0.000 (  0.676)f1:   0.000 (  0.000)
2023-11-30 09:12:04,660 Test: [  34/39]  Time: 0.064 (0.182)  Loss:   1.701 ( 0.748)  Acc@1:   0.000 ( 63.571)  Acc@5: 100.000 (100.000)precision:   0.000 (  0.000)recall:   0.000 (  0.000)soec:   0.000 (  0.657)f1:   0.000 (  0.000)
2023-11-30 09:12:04,725 Test: [  35/39]  Time: 0.065 (0.179)  Loss:   1.713 ( 0.775)  Acc@1:   0.000 ( 61.806)  Acc@5: 100.000 (100.000)precision:   0.000 (  0.000)recall:   0.000 (  0.000)soec:   0.000 (  0.639)f1:   0.000 (  0.000)
2023-11-30 09:12:05,032 Test: [  36/39]  Time: 0.306 (0.182)  Loss:   1.665 ( 0.799)  Acc@1:   0.000 ( 60.135)  Acc@5: 100.000 (100.000)precision:   0.000 (  0.000)recall:   0.000 (  0.000)soec:   0.000 (  0.622)f1:   0.000 (  0.000)
2023-11-30 09:12:05,615 Test: [  37/39]  Time: 0.583 (0.193)  Loss:   1.448 ( 0.816)  Acc@1:   9.375 ( 58.799)  Acc@5: 100.000 (100.000)precision:   1.000 (  0.026)recall:   0.094 (  0.002)soec:   0.000 (  0.605)f1:   0.171 (  0.005)
2023-11-30 09:12:05,676 Test: [  38/39]  Time: 0.061 (0.189)  Loss:   1.505 ( 0.834)  Acc@1:   3.125 ( 57.372)  Acc@5: 100.000 (100.000)precision:   1.000 (  0.051)recall:   0.031 (  0.003)soec:   0.000 (  0.590)f1:   0.061 (  0.006)
2023-11-30 09:12:05,876 Test: [  39/39]  Time: 0.200 (0.189)  Loss:   1.277 ( 0.834)  Acc@1:   0.000 ( 57.280)  Acc@5: 100.000 (100.000)precision:   0.000 (  0.051)recall:   0.000 (  0.003)soec:   0.000 (  0.589)f1:   0.000 (  0.006)
2023-11-30 09:12:06,080 Current checkpoints:
 ('./output/train/20231130-091145-efficientnet_b0-259/checkpoint-0.pth.tar', 57.28)

2023-11-30 09:12:06,080 *** Best metric: 57.28 (epoch 0)

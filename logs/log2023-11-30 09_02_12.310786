2023-11-30 09:02:12,366 Training with a single process on 1 device (cuda:0).
2023-11-30 09:02:12,583 Model efficientnet_b0 created, param count:8733680
2023-11-30 09:02:12,583 Data processing configuration for current model + dataset:
2023-11-30 09:02:12,583 	input_size: (3, 259, 259)
2023-11-30 09:02:12,583 	interpolation: bicubic
2023-11-30 09:02:12,583 	mean: (0.485, 0.456, 0.406)
2023-11-30 09:02:12,583 	std: (0.229, 0.224, 0.225)
2023-11-30 09:02:12,583 	crop_pct: 0.875
2023-11-30 09:02:12,583 	crop_mode: center
2023-11-30 09:02:15,075 AMP not enabled. Training in float32.
2023-11-30 09:02:15,118 Scheduled epochs: 1. LR stepped per epoch.
2023-11-30 09:02:17,326 FLOPs: 39.779662336 GFLOPs
2023-11-30 09:02:18,442 Train: 0 [   0/39 (  0%)]  Loss: 1.38 (1.38)  Time: 3.321s,    9.63/s  (3.321s,    9.63/s)  LR: 1.000e-05  Data: 1.068 (1.068)
2023-11-30 09:02:18,707 Train: 0 [   1/39 (  3%)]  Loss: 0.876 (1.13)  Time: 0.265s,  120.85/s  (1.793s,   17.85/s)  LR: 1.000e-05  Data: 0.008 (0.538)
2023-11-30 09:02:18,967 Train: 0 [   2/39 (  5%)]  Loss: 0.998 (1.09)  Time: 0.260s,  123.06/s  (1.282s,   24.96/s)  LR: 1.000e-05  Data: 0.003 (0.360)
2023-11-30 09:02:19,228 Train: 0 [   3/39 (  8%)]  Loss: 0.736 (0.998)  Time: 0.262s,  122.35/s  (1.027s,   31.16/s)  LR: 1.000e-05  Data: 0.004 (0.271)
2023-11-30 09:02:19,492 Train: 0 [   4/39 ( 11%)]  Loss: 0.971 (0.993)  Time: 0.264s,  121.35/s  (0.874s,   36.60/s)  LR: 1.000e-05  Data: 0.006 (0.218)
2023-11-30 09:02:19,754 Train: 0 [   5/39 ( 13%)]  Loss: 1.26 (1.04)  Time: 0.262s,  122.17/s  (0.772s,   41.44/s)  LR: 1.000e-05  Data: 0.004 (0.182)
2023-11-30 09:02:20,014 Train: 0 [   6/39 ( 16%)]  Loss: 1.23 (1.06)  Time: 0.260s,  122.98/s  (0.699s,   45.77/s)  LR: 1.000e-05  Data: 0.003 (0.157)
2023-11-30 09:02:20,275 Train: 0 [   7/39 ( 18%)]  Loss: 0.919 (1.05)  Time: 0.261s,  122.80/s  (0.644s,   49.67/s)  LR: 1.000e-05  Data: 0.004 (0.138)
2023-11-30 09:02:20,537 Train: 0 [   8/39 ( 21%)]  Loss: 1.93 (1.14)  Time: 0.262s,  122.18/s  (0.602s,   53.17/s)  LR: 1.000e-05  Data: 0.004 (0.123)
2023-11-30 09:02:20,799 Train: 0 [   9/39 ( 24%)]  Loss: 1.46 (1.18)  Time: 0.262s,  122.20/s  (0.568s,   56.36/s)  LR: 1.000e-05  Data: 0.005 (0.111)
2023-11-30 09:02:21,061 Train: 0 [  10/39 ( 26%)]  Loss: 1.78 (1.23)  Time: 0.262s,  122.15/s  (0.540s,   59.26/s)  LR: 1.000e-05  Data: 0.004 (0.101)
2023-11-30 09:02:21,321 Train: 0 [  11/39 ( 29%)]  Loss: 1.21 (1.23)  Time: 0.261s,  122.80/s  (0.517s,   61.93/s)  LR: 1.000e-05  Data: 0.004 (0.093)
2023-11-30 09:02:21,583 Train: 0 [  12/39 ( 32%)]  Loss: 1.31 (1.23)  Time: 0.262s,  122.18/s  (0.497s,   64.37/s)  LR: 1.000e-05  Data: 0.004 (0.086)
2023-11-30 09:02:21,844 Train: 0 [  13/39 ( 34%)]  Loss: 1.91 (1.28)  Time: 0.261s,  122.42/s  (0.480s,   66.63/s)  LR: 1.000e-05  Data: 0.004 (0.080)
2023-11-30 09:02:22,107 Train: 0 [  14/39 ( 37%)]  Loss: 1.12 (1.27)  Time: 0.262s,  122.10/s  (0.466s,   68.71/s)  LR: 1.000e-05  Data: 0.004 (0.075)
2023-11-30 09:02:22,368 Train: 0 [  15/39 ( 39%)]  Loss: 1.05 (1.26)  Time: 0.261s,  122.46/s  (0.453s,   70.65/s)  LR: 1.000e-05  Data: 0.004 (0.071)
2023-11-30 09:02:22,630 Train: 0 [  16/39 ( 42%)]  Loss: 2.06 (1.31)  Time: 0.262s,  122.23/s  (0.442s,   72.45/s)  LR: 1.000e-05  Data: 0.004 (0.067)
2023-11-30 09:02:22,892 Train: 0 [  17/39 ( 45%)]  Loss: 0.833 (1.28)  Time: 0.262s,  121.99/s  (0.432s,   74.12/s)  LR: 1.000e-05  Data: 0.004 (0.064)
2023-11-30 09:02:23,154 Train: 0 [  18/39 ( 47%)]  Loss: 0.947 (1.26)  Time: 0.262s,  122.25/s  (0.423s,   75.69/s)  LR: 1.000e-05  Data: 0.005 (0.060)
2023-11-30 09:02:23,415 Train: 0 [  19/39 ( 50%)]  Loss: 1.56 (1.28)  Time: 0.261s,  122.46/s  (0.415s,   77.16/s)  LR: 1.000e-05  Data: 0.004 (0.058)
2023-11-30 09:02:23,677 Train: 0 [  20/39 ( 53%)]  Loss: 0.965 (1.26)  Time: 0.262s,  122.27/s  (0.407s,   78.54/s)  LR: 1.000e-05  Data: 0.004 (0.055)
2023-11-30 09:02:23,938 Train: 0 [  21/39 ( 55%)]  Loss: 1.08 (1.25)  Time: 0.262s,  122.26/s  (0.401s,   79.84/s)  LR: 1.000e-05  Data: 0.004 (0.053)
2023-11-30 09:02:24,201 Train: 0 [  22/39 ( 58%)]  Loss: 1.86 (1.28)  Time: 0.262s,  121.97/s  (0.395s,   81.06/s)  LR: 1.000e-05  Data: 0.005 (0.051)
2023-11-30 09:02:24,463 Train: 0 [  23/39 ( 61%)]  Loss: 0.941 (1.27)  Time: 0.262s,  122.15/s  (0.389s,   82.21/s)  LR: 1.000e-05  Data: 0.004 (0.049)
2023-11-30 09:02:24,725 Train: 0 [  24/39 ( 63%)]  Loss: 1.31 (1.27)  Time: 0.262s,  121.98/s  (0.384s,   83.29/s)  LR: 1.000e-05  Data: 0.005 (0.047)
2023-11-30 09:02:24,987 Train: 0 [  25/39 ( 66%)]  Loss: 1.06 (1.26)  Time: 0.262s,  122.20/s  (0.379s,   84.33/s)  LR: 1.000e-05  Data: 0.005 (0.045)
2023-11-30 09:02:25,249 Train: 0 [  26/39 ( 68%)]  Loss: 0.998 (1.25)  Time: 0.262s,  122.30/s  (0.375s,   85.31/s)  LR: 1.000e-05  Data: 0.004 (0.044)
2023-11-30 09:02:25,510 Train: 0 [  27/39 ( 71%)]  Loss: 0.885 (1.24)  Time: 0.261s,  122.45/s  (0.371s,   86.24/s)  LR: 1.000e-05  Data: 0.004 (0.042)
2023-11-30 09:02:25,772 Train: 0 [  28/39 ( 74%)]  Loss: 1.86 (1.26)  Time: 0.262s,  122.20/s  (0.367s,   87.13/s)  LR: 1.000e-05  Data: 0.004 (0.041)
2023-11-30 09:02:26,034 Train: 0 [  29/39 ( 76%)]  Loss: 0.989 (1.25)  Time: 0.262s,  122.26/s  (0.364s,   87.97/s)  LR: 1.000e-05  Data: 0.004 (0.040)
2023-11-30 09:02:26,294 Train: 0 [  30/39 ( 79%)]  Loss: 1.07 (1.24)  Time: 0.261s,  122.65/s  (0.360s,   88.78/s)  LR: 1.000e-05  Data: 0.004 (0.039)
2023-11-30 09:02:26,554 Train: 0 [  31/39 ( 82%)]  Loss: 1.67 (1.26)  Time: 0.260s,  123.20/s  (0.357s,   89.56/s)  LR: 1.000e-05  Data: 0.004 (0.038)
2023-11-30 09:02:26,815 Train: 0 [  32/39 ( 84%)]  Loss: 1.05 (1.25)  Time: 0.261s,  122.83/s  (0.354s,   90.30/s)  LR: 1.000e-05  Data: 0.004 (0.037)
2023-11-30 09:02:27,075 Train: 0 [  33/39 ( 87%)]  Loss: 1.36 (1.25)  Time: 0.260s,  123.09/s  (0.352s,   91.01/s)  LR: 1.000e-05  Data: 0.004 (0.036)
2023-11-30 09:02:27,334 Train: 0 [  34/39 ( 89%)]  Loss: 0.979 (1.25)  Time: 0.260s,  123.18/s  (0.349s,   91.70/s)  LR: 1.000e-05  Data: 0.004 (0.035)
2023-11-30 09:02:27,595 Train: 0 [  35/39 ( 92%)]  Loss: 1.12 (1.24)  Time: 0.261s,  122.80/s  (0.347s,   92.35/s)  LR: 1.000e-05  Data: 0.004 (0.034)
2023-11-30 09:02:27,856 Train: 0 [  36/39 ( 95%)]  Loss: 1.26 (1.24)  Time: 0.261s,  122.61/s  (0.344s,   92.97/s)  LR: 1.000e-05  Data: 0.004 (0.033)
2023-11-30 09:02:28,116 Train: 0 [  37/39 ( 97%)]  Loss: 1.01 (1.24)  Time: 0.260s,  123.01/s  (0.342s,   93.57/s)  LR: 1.000e-05  Data: 0.004 (0.032)
2023-11-30 09:02:28,372 Train: 0 [  38/39 (100%)]  Loss: 2.58 (1.27)  Time: 0.256s,  125.09/s  (0.340s,   94.18/s)  LR: 1.000e-05  Data: 0.000 (0.032)
2023-11-30 09:02:29,519 Test: [   0/39]  Time: 1.143 (1.143)  Loss:   0.187 ( 0.187)  Acc@1: 100.000 (100.000)  Acc@5: 100.000 (100.000)precision:   0.000 (  0.000)recall:   0.000 (  0.000)soec:   1.000 (  1.000)f1:   0.000 (  0.000)
2023-11-30 09:02:29,583 Test: [   1/39]  Time: 0.064 (0.604)  Loss:   0.184 ( 0.185)  Acc@1: 100.000 (100.000)  Acc@5: 100.000 (100.000)precision:   0.000 (  0.000)recall:   0.000 (  0.000)soec:   1.000 (  1.000)f1:   0.000 (  0.000)
2023-11-30 09:02:29,646 Test: [   2/39]  Time: 0.064 (0.424)  Loss:   0.186 ( 0.186)  Acc@1: 100.000 (100.000)  Acc@5: 100.000 (100.000)precision:   0.000 (  0.000)recall:   0.000 (  0.000)soec:   1.000 (  1.000)f1:   0.000 (  0.000)
2023-11-30 09:02:30,042 Test: [   3/39]  Time: 0.396 (0.417)  Loss:   0.187 ( 0.186)  Acc@1: 100.000 (100.000)  Acc@5: 100.000 (100.000)precision:   0.000 (  0.000)recall:   0.000 (  0.000)soec:   1.000 (  1.000)f1:   0.000 (  0.000)
2023-11-30 09:02:30,145 Test: [   4/39]  Time: 0.103 (0.354)  Loss:   0.188 ( 0.186)  Acc@1: 100.000 (100.000)  Acc@5: 100.000 (100.000)precision:   0.000 (  0.000)recall:   0.000 (  0.000)soec:   1.000 (  1.000)f1:   0.000 (  0.000)
2023-11-30 09:02:30,209 Test: [   5/39]  Time: 0.064 (0.306)  Loss:   0.191 ( 0.187)  Acc@1: 100.000 (100.000)  Acc@5: 100.000 (100.000)precision:   0.000 (  0.000)recall:   0.000 (  0.000)soec:   1.000 (  1.000)f1:   0.000 (  0.000)
2023-11-30 09:02:30,272 Test: [   6/39]  Time: 0.064 (0.271)  Loss:   0.186 ( 0.187)  Acc@1: 100.000 (100.000)  Acc@5: 100.000 (100.000)precision:   0.000 (  0.000)recall:   0.000 (  0.000)soec:   1.000 (  1.000)f1:   0.000 (  0.000)
2023-11-30 09:02:30,644 Test: [   7/39]  Time: 0.372 (0.284)  Loss:   0.185 ( 0.187)  Acc@1: 100.000 (100.000)  Acc@5: 100.000 (100.000)precision:   0.000 (  0.000)recall:   0.000 (  0.000)soec:   1.000 (  1.000)f1:   0.000 (  0.000)
2023-11-30 09:02:30,812 Test: [   8/39]  Time: 0.168 (0.271)  Loss:   0.185 ( 0.187)  Acc@1: 100.000 (100.000)  Acc@5: 100.000 (100.000)precision:   0.000 (  0.000)recall:   0.000 (  0.000)soec:   1.000 (  1.000)f1:   0.000 (  0.000)
2023-11-30 09:02:30,875 Test: [   9/39]  Time: 0.064 (0.250)  Loss:   0.188 ( 0.187)  Acc@1: 100.000 (100.000)  Acc@5: 100.000 (100.000)precision:   0.000 (  0.000)recall:   0.000 (  0.000)soec:   1.000 (  1.000)f1:   0.000 (  0.000)
2023-11-30 09:02:30,939 Test: [  10/39]  Time: 0.064 (0.233)  Loss:   0.187 ( 0.187)  Acc@1: 100.000 (100.000)  Acc@5: 100.000 (100.000)precision:   0.000 (  0.000)recall:   0.000 (  0.000)soec:   1.000 (  1.000)f1:   0.000 (  0.000)
2023-11-30 09:02:31,284 Test: [  11/39]  Time: 0.345 (0.242)  Loss:   0.185 ( 0.187)  Acc@1: 100.000 (100.000)  Acc@5: 100.000 (100.000)precision:   0.000 (  0.000)recall:   0.000 (  0.000)soec:   1.000 (  1.000)f1:   0.000 (  0.000)
2023-11-30 09:02:31,457 Test: [  12/39]  Time: 0.173 (0.237)  Loss:   0.187 ( 0.187)  Acc@1: 100.000 (100.000)  Acc@5: 100.000 (100.000)precision:   0.000 (  0.000)recall:   0.000 (  0.000)soec:   1.000 (  1.000)f1:   0.000 (  0.000)
2023-11-30 09:02:31,521 Test: [  13/39]  Time: 0.064 (0.225)  Loss:   0.186 ( 0.187)  Acc@1: 100.000 (100.000)  Acc@5: 100.000 (100.000)precision:   0.000 (  0.000)recall:   0.000 (  0.000)soec:   1.000 (  1.000)f1:   0.000 (  0.000)
2023-11-30 09:02:31,585 Test: [  14/39]  Time: 0.064 (0.214)  Loss:   0.187 ( 0.187)  Acc@1: 100.000 (100.000)  Acc@5: 100.000 (100.000)precision:   0.000 (  0.000)recall:   0.000 (  0.000)soec:   1.000 (  1.000)f1:   0.000 (  0.000)
2023-11-30 09:02:31,949 Test: [  15/39]  Time: 0.364 (0.223)  Loss:   0.187 ( 0.187)  Acc@1: 100.000 (100.000)  Acc@5: 100.000 (100.000)precision:   0.000 (  0.000)recall:   0.000 (  0.000)soec:   1.000 (  1.000)f1:   0.000 (  0.000)
2023-11-30 09:02:32,113 Test: [  16/39]  Time: 0.164 (0.220)  Loss:   0.186 ( 0.187)  Acc@1: 100.000 (100.000)  Acc@5: 100.000 (100.000)precision:   0.000 (  0.000)recall:   0.000 (  0.000)soec:   1.000 (  1.000)f1:   0.000 (  0.000)
2023-11-30 09:02:32,177 Test: [  17/39]  Time: 0.064 (0.211)  Loss:   0.184 ( 0.187)  Acc@1: 100.000 (100.000)  Acc@5: 100.000 (100.000)precision:   0.000 (  0.000)recall:   0.000 (  0.000)soec:   1.000 (  1.000)f1:   0.000 (  0.000)
2023-11-30 09:02:32,241 Test: [  18/39]  Time: 0.064 (0.203)  Loss:   0.186 ( 0.187)  Acc@1: 100.000 (100.000)  Acc@5: 100.000 (100.000)precision:   0.000 (  0.000)recall:   0.000 (  0.000)soec:   1.000 (  1.000)f1:   0.000 (  0.000)
2023-11-30 09:02:32,566 Test: [  19/39]  Time: 0.325 (0.210)  Loss:   0.185 ( 0.186)  Acc@1: 100.000 (100.000)  Acc@5: 100.000 (100.000)precision:   0.000 (  0.000)recall:   0.000 (  0.000)soec:   1.000 (  1.000)f1:   0.000 (  0.000)
2023-11-30 09:02:32,742 Test: [  20/39]  Time: 0.176 (0.208)  Loss:   0.185 ( 0.186)  Acc@1: 100.000 (100.000)  Acc@5: 100.000 (100.000)precision:   0.000 (  0.000)recall:   0.000 (  0.000)soec:   1.000 (  1.000)f1:   0.000 (  0.000)
2023-11-30 09:02:32,805 Test: [  21/39]  Time: 0.064 (0.201)  Loss:   0.183 ( 0.186)  Acc@1: 100.000 (100.000)  Acc@5: 100.000 (100.000)precision:   0.000 (  0.000)recall:   0.000 (  0.000)soec:   1.000 (  1.000)f1:   0.000 (  0.000)
2023-11-30 09:02:32,869 Test: [  22/39]  Time: 0.064 (0.195)  Loss:   1.355 ( 0.237)  Acc@1:  25.000 ( 96.739)  Acc@5: 100.000 (100.000)precision:   0.000 (  0.000)recall:   0.000 (  0.000)soec:   1.000 (  1.000)f1:   0.000 (  0.000)
2023-11-30 09:02:33,159 Test: [  23/39]  Time: 0.289 (0.199)  Loss:   1.764 ( 0.301)  Acc@1:   0.000 ( 92.708)  Acc@5: 100.000 (100.000)precision:   0.000 (  0.000)recall:   0.000 (  0.000)soec:   0.000 (  0.958)f1:   0.000 (  0.000)
2023-11-30 09:02:33,370 Test: [  24/39]  Time: 0.212 (0.200)  Loss:   1.762 ( 0.359)  Acc@1:   0.000 ( 89.000)  Acc@5: 100.000 (100.000)precision:   0.000 (  0.000)recall:   0.000 (  0.000)soec:   0.000 (  0.920)f1:   0.000 (  0.000)
2023-11-30 09:02:33,434 Test: [  25/39]  Time: 0.064 (0.195)  Loss:   1.772 ( 0.413)  Acc@1:   0.000 ( 85.577)  Acc@5: 100.000 (100.000)precision:   0.000 (  0.000)recall:   0.000 (  0.000)soec:   0.000 (  0.885)f1:   0.000 (  0.000)
2023-11-30 09:02:33,498 Test: [  26/39]  Time: 0.064 (0.190)  Loss:   1.765 ( 0.464)  Acc@1:   0.000 ( 82.407)  Acc@5: 100.000 (100.000)precision:   0.000 (  0.000)recall:   0.000 (  0.000)soec:   0.000 (  0.852)f1:   0.000 (  0.000)
2023-11-30 09:02:33,786 Test: [  27/39]  Time: 0.288 (0.193)  Loss:   1.771 ( 0.510)  Acc@1:   0.000 ( 79.464)  Acc@5: 100.000 (100.000)precision:   0.000 (  0.000)recall:   0.000 (  0.000)soec:   0.000 (  0.821)f1:   0.000 (  0.000)
2023-11-30 09:02:33,963 Test: [  28/39]  Time: 0.178 (0.193)  Loss:   1.777 ( 0.554)  Acc@1:   0.000 ( 76.724)  Acc@5: 100.000 (100.000)precision:   0.000 (  0.000)recall:   0.000 (  0.000)soec:   0.000 (  0.793)f1:   0.000 (  0.000)
2023-11-30 09:02:34,027 Test: [  29/39]  Time: 0.064 (0.188)  Loss:   1.777 ( 0.595)  Acc@1:   0.000 ( 74.167)  Acc@5: 100.000 (100.000)precision:   0.000 (  0.000)recall:   0.000 (  0.000)soec:   0.000 (  0.767)f1:   0.000 (  0.000)
2023-11-30 09:02:34,091 Test: [  30/39]  Time: 0.064 (0.184)  Loss:   1.772 ( 0.633)  Acc@1:   0.000 ( 71.774)  Acc@5: 100.000 (100.000)precision:   0.000 (  0.000)recall:   0.000 (  0.000)soec:   0.000 (  0.742)f1:   0.000 (  0.000)
2023-11-30 09:02:34,410 Test: [  31/39]  Time: 0.320 (0.189)  Loss:   1.779 ( 0.668)  Acc@1:   0.000 ( 69.531)  Acc@5: 100.000 (100.000)precision:   0.000 (  0.000)recall:   0.000 (  0.000)soec:   0.000 (  0.719)f1:   0.000 (  0.000)
2023-11-30 09:02:34,576 Test: [  32/39]  Time: 0.166 (0.188)  Loss:   1.762 ( 0.702)  Acc@1:   0.000 ( 67.424)  Acc@5: 100.000 (100.000)precision:   0.000 (  0.000)recall:   0.000 (  0.000)soec:   0.000 (  0.697)f1:   0.000 (  0.000)
2023-11-30 09:02:34,639 Test: [  33/39]  Time: 0.064 (0.184)  Loss:   1.771 ( 0.733)  Acc@1:   0.000 ( 65.441)  Acc@5: 100.000 (100.000)precision:   0.000 (  0.000)recall:   0.000 (  0.000)soec:   0.000 (  0.676)f1:   0.000 (  0.000)
2023-11-30 09:02:34,703 Test: [  34/39]  Time: 0.064 (0.181)  Loss:   1.764 ( 0.763)  Acc@1:   0.000 ( 63.571)  Acc@5: 100.000 (100.000)precision:   0.000 (  0.000)recall:   0.000 (  0.000)soec:   0.000 (  0.657)f1:   0.000 (  0.000)
2023-11-30 09:02:34,773 Test: [  35/39]  Time: 0.070 (0.178)  Loss:   1.777 ( 0.791)  Acc@1:   0.000 ( 61.806)  Acc@5: 100.000 (100.000)precision:   0.000 (  0.000)recall:   0.000 (  0.000)soec:   0.000 (  0.639)f1:   0.000 (  0.000)
2023-11-30 09:02:35,093 Test: [  36/39]  Time: 0.319 (0.182)  Loss:   1.727 ( 0.816)  Acc@1:   0.000 ( 60.135)  Acc@5: 100.000 (100.000)precision:   0.000 (  0.000)recall:   0.000 (  0.000)soec:   0.000 (  0.622)f1:   0.000 (  0.000)
2023-11-30 09:02:35,737 Test: [  37/39]  Time: 0.644 (0.194)  Loss:   1.502 ( 0.834)  Acc@1:   6.250 ( 58.717)  Acc@5: 100.000 (100.000)precision:   1.000 (  0.026)recall:   0.062 (  0.002)soec:   0.000 (  0.605)f1:   0.118 (  0.003)
2023-11-30 09:02:35,798 Test: [  38/39]  Time: 0.061 (0.190)  Loss:   1.562 ( 0.853)  Acc@1:   3.125 ( 57.292)  Acc@5: 100.000 (100.000)precision:   1.000 (  0.051)recall:   0.031 (  0.002)soec:   0.000 (  0.590)f1:   0.061 (  0.005)
2023-11-30 09:02:36,002 Test: [  39/39]  Time: 0.204 (0.191)  Loss:   1.326 ( 0.853)  Acc@1:   0.000 ( 57.200)  Acc@5: 100.000 (100.000)precision:   0.000 (  0.051)recall:   0.000 (  0.002)soec:   0.000 (  0.589)f1:   0.000 (  0.005)
2023-11-30 09:02:36,205 Current checkpoints:
 ('./output/train/20231130-090215-efficientnet_b0-259/checkpoint-0.pth.tar', 57.2)

2023-11-30 09:02:36,205 *** Best metric: 57.2 (epoch 0)

2023-11-30 09:00:17,817 Training with a single process on 1 device (cuda:0).
2023-11-30 09:00:18,034 Model efficientnet_b0 created, param count:8733680
2023-11-30 09:00:18,035 Data processing configuration for current model + dataset:
2023-11-30 09:00:18,035 	input_size: (3, 259, 259)
2023-11-30 09:00:18,035 	interpolation: bicubic
2023-11-30 09:00:18,035 	mean: (0.485, 0.456, 0.406)
2023-11-30 09:00:18,035 	std: (0.229, 0.224, 0.225)
2023-11-30 09:00:18,035 	crop_pct: 0.875
2023-11-30 09:00:18,035 	crop_mode: center
2023-11-30 09:00:20,608 AMP not enabled. Training in float32.
2023-11-30 09:00:20,651 Scheduled epochs: 1. LR stepped per epoch.
2023-11-30 09:00:22,876 FLOPs: 39.779662336 GFLOPs
2023-11-30 09:00:24,046 Train: 0 [   0/39 (  0%)]  Loss: 1.38 (1.38)  Time: 3.393s,    9.43/s  (3.393s,    9.43/s)  LR: 1.000e-05  Data: 1.028 (1.028)
2023-11-30 09:00:24,306 Train: 0 [   1/39 (  3%)]  Loss: 0.876 (1.13)  Time: 0.260s,  122.89/s  (1.827s,   17.52/s)  LR: 1.000e-05  Data: 0.003 (0.516)
2023-11-30 09:00:24,568 Train: 0 [   2/39 (  5%)]  Loss: 0.998 (1.09)  Time: 0.262s,  122.21/s  (1.305s,   24.52/s)  LR: 1.000e-05  Data: 0.005 (0.345)
2023-11-30 09:00:24,833 Train: 0 [   3/39 (  8%)]  Loss: 0.736 (0.998)  Time: 0.264s,  120.99/s  (1.045s,   30.63/s)  LR: 1.000e-05  Data: 0.007 (0.261)
2023-11-30 09:00:25,093 Train: 0 [   4/39 ( 11%)]  Loss: 0.971 (0.993)  Time: 0.260s,  122.99/s  (0.888s,   36.04/s)  LR: 1.000e-05  Data: 0.003 (0.209)
2023-11-30 09:00:25,353 Train: 0 [   5/39 ( 13%)]  Loss: 1.26 (1.04)  Time: 0.260s,  123.03/s  (0.783s,   40.85/s)  LR: 1.000e-05  Data: 0.003 (0.175)
2023-11-30 09:00:25,615 Train: 0 [   6/39 ( 16%)]  Loss: 1.23 (1.06)  Time: 0.262s,  122.26/s  (0.709s,   45.15/s)  LR: 1.000e-05  Data: 0.005 (0.151)
2023-11-30 09:00:25,878 Train: 0 [   7/39 ( 18%)]  Loss: 0.919 (1.05)  Time: 0.263s,  121.63/s  (0.653s,   49.00/s)  LR: 1.000e-05  Data: 0.005 (0.132)
2023-11-30 09:00:26,138 Train: 0 [   8/39 ( 21%)]  Loss: 1.93 (1.14)  Time: 0.260s,  122.98/s  (0.609s,   52.51/s)  LR: 1.000e-05  Data: 0.003 (0.118)
2023-11-30 09:00:26,400 Train: 0 [   9/39 ( 24%)]  Loss: 1.46 (1.18)  Time: 0.262s,  122.30/s  (0.575s,   55.69/s)  LR: 1.000e-05  Data: 0.005 (0.107)
2023-11-30 09:00:26,661 Train: 0 [  10/39 ( 26%)]  Loss: 1.78 (1.23)  Time: 0.262s,  122.35/s  (0.546s,   58.59/s)  LR: 1.000e-05  Data: 0.005 (0.097)
2023-11-30 09:00:26,922 Train: 0 [  11/39 ( 29%)]  Loss: 1.21 (1.23)  Time: 0.261s,  122.57/s  (0.522s,   61.25/s)  LR: 1.000e-05  Data: 0.005 (0.090)
2023-11-30 09:00:27,184 Train: 0 [  12/39 ( 32%)]  Loss: 1.31 (1.23)  Time: 0.261s,  122.40/s  (0.502s,   63.70/s)  LR: 1.000e-05  Data: 0.005 (0.083)
2023-11-30 09:00:27,446 Train: 0 [  13/39 ( 34%)]  Loss: 1.91 (1.28)  Time: 0.262s,  122.16/s  (0.485s,   65.96/s)  LR: 1.000e-05  Data: 0.004 (0.077)
2023-11-30 09:00:27,707 Train: 0 [  14/39 ( 37%)]  Loss: 1.12 (1.27)  Time: 0.262s,  122.21/s  (0.470s,   68.04/s)  LR: 1.000e-05  Data: 0.005 (0.073)
2023-11-30 09:00:27,970 Train: 0 [  15/39 ( 39%)]  Loss: 1.05 (1.26)  Time: 0.262s,  122.05/s  (0.457s,   69.98/s)  LR: 1.000e-05  Data: 0.005 (0.068)
2023-11-30 09:00:28,231 Train: 0 [  16/39 ( 42%)]  Loss: 2.06 (1.31)  Time: 0.262s,  122.24/s  (0.446s,   71.78/s)  LR: 1.000e-05  Data: 0.005 (0.065)
2023-11-30 09:00:28,493 Train: 0 [  17/39 ( 45%)]  Loss: 0.833 (1.28)  Time: 0.262s,  122.20/s  (0.436s,   73.47/s)  LR: 1.000e-05  Data: 0.005 (0.061)
2023-11-30 09:00:28,755 Train: 0 [  18/39 ( 47%)]  Loss: 0.948 (1.26)  Time: 0.262s,  122.33/s  (0.426s,   75.05/s)  LR: 1.000e-05  Data: 0.004 (0.058)
2023-11-30 09:00:29,016 Train: 0 [  19/39 ( 50%)]  Loss: 1.56 (1.28)  Time: 0.262s,  122.28/s  (0.418s,   76.52/s)  LR: 1.000e-05  Data: 0.005 (0.056)
2023-11-30 09:00:29,278 Train: 0 [  20/39 ( 53%)]  Loss: 0.965 (1.26)  Time: 0.262s,  122.20/s  (0.411s,   77.91/s)  LR: 1.000e-05  Data: 0.005 (0.053)
2023-11-30 09:00:29,540 Train: 0 [  21/39 ( 55%)]  Loss: 1.08 (1.25)  Time: 0.262s,  122.22/s  (0.404s,   79.22/s)  LR: 1.000e-05  Data: 0.005 (0.051)
2023-11-30 09:00:29,801 Train: 0 [  22/39 ( 58%)]  Loss: 1.86 (1.28)  Time: 0.261s,  122.58/s  (0.398s,   80.45/s)  LR: 1.000e-05  Data: 0.004 (0.049)
2023-11-30 09:00:30,063 Train: 0 [  23/39 ( 61%)]  Loss: 0.941 (1.27)  Time: 0.262s,  122.28/s  (0.392s,   81.62/s)  LR: 1.000e-05  Data: 0.005 (0.047)
2023-11-30 09:00:30,325 Train: 0 [  24/39 ( 63%)]  Loss: 1.31 (1.27)  Time: 0.262s,  122.14/s  (0.387s,   82.71/s)  LR: 1.000e-05  Data: 0.005 (0.045)
2023-11-30 09:00:30,586 Train: 0 [  25/39 ( 66%)]  Loss: 1.06 (1.26)  Time: 0.262s,  122.32/s  (0.382s,   83.76/s)  LR: 1.000e-05  Data: 0.005 (0.044)
2023-11-30 09:00:30,848 Train: 0 [  26/39 ( 68%)]  Loss: 0.999 (1.25)  Time: 0.262s,  122.34/s  (0.378s,   84.75/s)  LR: 1.000e-05  Data: 0.004 (0.042)
2023-11-30 09:00:31,110 Train: 0 [  27/39 ( 71%)]  Loss: 0.885 (1.24)  Time: 0.262s,  122.26/s  (0.373s,   85.69/s)  LR: 1.000e-05  Data: 0.005 (0.041)
2023-11-30 09:00:31,371 Train: 0 [  28/39 ( 74%)]  Loss: 1.86 (1.26)  Time: 0.262s,  122.30/s  (0.370s,   86.58/s)  LR: 1.000e-05  Data: 0.005 (0.040)
2023-11-30 09:00:31,633 Train: 0 [  29/39 ( 76%)]  Loss: 0.989 (1.25)  Time: 0.261s,  122.39/s  (0.366s,   87.43/s)  LR: 1.000e-05  Data: 0.005 (0.039)
2023-11-30 09:00:31,894 Train: 0 [  30/39 ( 79%)]  Loss: 1.07 (1.24)  Time: 0.261s,  122.68/s  (0.363s,   88.25/s)  LR: 1.000e-05  Data: 0.004 (0.037)
2023-11-30 09:00:32,154 Train: 0 [  31/39 ( 82%)]  Loss: 1.67 (1.26)  Time: 0.260s,  122.95/s  (0.359s,   89.04/s)  LR: 1.000e-05  Data: 0.004 (0.036)
2023-11-30 09:00:32,415 Train: 0 [  32/39 ( 84%)]  Loss: 1.05 (1.25)  Time: 0.261s,  122.53/s  (0.356s,   89.78/s)  LR: 1.000e-05  Data: 0.004 (0.035)
2023-11-30 09:00:32,675 Train: 0 [  33/39 ( 87%)]  Loss: 1.35 (1.25)  Time: 0.260s,  123.14/s  (0.354s,   90.50/s)  LR: 1.000e-05  Data: 0.004 (0.035)
2023-11-30 09:00:32,935 Train: 0 [  34/39 ( 89%)]  Loss: 0.982 (1.25)  Time: 0.260s,  123.17/s  (0.351s,   91.19/s)  LR: 1.000e-05  Data: 0.004 (0.034)
2023-11-30 09:00:33,194 Train: 0 [  35/39 ( 92%)]  Loss: 1.13 (1.24)  Time: 0.260s,  123.31/s  (0.348s,   91.86/s)  LR: 1.000e-05  Data: 0.004 (0.033)
2023-11-30 09:00:33,454 Train: 0 [  36/39 ( 95%)]  Loss: 1.28 (1.24)  Time: 0.259s,  123.32/s  (0.346s,   92.49/s)  LR: 1.000e-05  Data: 0.004 (0.032)
2023-11-30 09:00:33,714 Train: 0 [  37/39 ( 97%)]  Loss: 1.01 (1.24)  Time: 0.260s,  123.21/s  (0.344s,   93.10/s)  LR: 1.000e-05  Data: 0.004 (0.031)
2023-11-30 09:00:33,969 Train: 0 [  38/39 (100%)]  Loss: 2.55 (1.27)  Time: 0.255s,  125.38/s  (0.341s,   93.72/s)  LR: 1.000e-05  Data: 0.000 (0.031)
2023-11-30 09:00:35,166 Test: [   0/39]  Time: 1.194 (1.194)  Loss:   0.192 ( 0.192)  Acc@1: 100.000 (100.000)  Acc@5: 100.000 (100.000)precision:   0.000 (  0.000)recall:   0.000 (  0.000)soec:   1.000 (  1.000)f1:   0.000 (  0.000)
2023-11-30 09:00:35,230 Test: [   1/39]  Time: 0.065 (0.629)  Loss:   0.189 ( 0.190)  Acc@1: 100.000 (100.000)  Acc@5: 100.000 (100.000)precision:   0.000 (  0.000)recall:   0.000 (  0.000)soec:   1.000 (  1.000)f1:   0.000 (  0.000)
2023-11-30 09:00:35,294 Test: [   2/39]  Time: 0.064 (0.441)  Loss:   0.192 ( 0.191)  Acc@1: 100.000 (100.000)  Acc@5: 100.000 (100.000)precision:   0.000 (  0.000)recall:   0.000 (  0.000)soec:   1.000 (  1.000)f1:   0.000 (  0.000)
2023-11-30 09:00:35,722 Test: [   3/39]  Time: 0.428 (0.438)  Loss:   0.193 ( 0.191)  Acc@1: 100.000 (100.000)  Acc@5: 100.000 (100.000)precision:   0.000 (  0.000)recall:   0.000 (  0.000)soec:   1.000 (  1.000)f1:   0.000 (  0.000)
2023-11-30 09:00:35,862 Test: [   4/39]  Time: 0.140 (0.378)  Loss:   0.193 ( 0.192)  Acc@1: 100.000 (100.000)  Acc@5: 100.000 (100.000)precision:   0.000 (  0.000)recall:   0.000 (  0.000)soec:   1.000 (  1.000)f1:   0.000 (  0.000)
2023-11-30 09:00:35,928 Test: [   5/39]  Time: 0.066 (0.326)  Loss:   0.196 ( 0.192)  Acc@1: 100.000 (100.000)  Acc@5: 100.000 (100.000)precision:   0.000 (  0.000)recall:   0.000 (  0.000)soec:   1.000 (  1.000)f1:   0.000 (  0.000)
2023-11-30 09:00:35,992 Test: [   6/39]  Time: 0.064 (0.289)  Loss:   0.192 ( 0.192)  Acc@1: 100.000 (100.000)  Acc@5: 100.000 (100.000)precision:   0.000 (  0.000)recall:   0.000 (  0.000)soec:   1.000 (  1.000)f1:   0.000 (  0.000)
2023-11-30 09:00:36,322 Test: [   7/39]  Time: 0.330 (0.294)  Loss:   0.190 ( 0.192)  Acc@1: 100.000 (100.000)  Acc@5: 100.000 (100.000)precision:   0.000 (  0.000)recall:   0.000 (  0.000)soec:   1.000 (  1.000)f1:   0.000 (  0.000)
2023-11-30 09:00:36,512 Test: [   8/39]  Time: 0.190 (0.282)  Loss:   0.191 ( 0.192)  Acc@1: 100.000 (100.000)  Acc@5: 100.000 (100.000)precision:   0.000 (  0.000)recall:   0.000 (  0.000)soec:   1.000 (  1.000)f1:   0.000 (  0.000)
2023-11-30 09:00:36,578 Test: [   9/39]  Time: 0.066 (0.261)  Loss:   0.193 ( 0.192)  Acc@1: 100.000 (100.000)  Acc@5: 100.000 (100.000)precision:   0.000 (  0.000)recall:   0.000 (  0.000)soec:   1.000 (  1.000)f1:   0.000 (  0.000)
2023-11-30 09:00:36,642 Test: [  10/39]  Time: 0.064 (0.243)  Loss:   0.193 ( 0.192)  Acc@1: 100.000 (100.000)  Acc@5: 100.000 (100.000)precision:   0.000 (  0.000)recall:   0.000 (  0.000)soec:   1.000 (  1.000)f1:   0.000 (  0.000)
2023-11-30 09:00:36,967 Test: [  11/39]  Time: 0.326 (0.250)  Loss:   0.191 ( 0.192)  Acc@1: 100.000 (100.000)  Acc@5: 100.000 (100.000)precision:   0.000 (  0.000)recall:   0.000 (  0.000)soec:   1.000 (  1.000)f1:   0.000 (  0.000)
2023-11-30 09:00:37,155 Test: [  12/39]  Time: 0.188 (0.245)  Loss:   0.192 ( 0.192)  Acc@1: 100.000 (100.000)  Acc@5: 100.000 (100.000)precision:   0.000 (  0.000)recall:   0.000 (  0.000)soec:   1.000 (  1.000)f1:   0.000 (  0.000)
2023-11-30 09:00:37,221 Test: [  13/39]  Time: 0.065 (0.232)  Loss:   0.191 ( 0.192)  Acc@1: 100.000 (100.000)  Acc@5: 100.000 (100.000)precision:   0.000 (  0.000)recall:   0.000 (  0.000)soec:   1.000 (  1.000)f1:   0.000 (  0.000)
2023-11-30 09:00:37,284 Test: [  14/39]  Time: 0.064 (0.221)  Loss:   0.193 ( 0.192)  Acc@1: 100.000 (100.000)  Acc@5: 100.000 (100.000)precision:   0.000 (  0.000)recall:   0.000 (  0.000)soec:   1.000 (  1.000)f1:   0.000 (  0.000)
2023-11-30 09:00:37,644 Test: [  15/39]  Time: 0.360 (0.229)  Loss:   0.193 ( 0.192)  Acc@1: 100.000 (100.000)  Acc@5: 100.000 (100.000)precision:   0.000 (  0.000)recall:   0.000 (  0.000)soec:   1.000 (  1.000)f1:   0.000 (  0.000)
2023-11-30 09:00:37,822 Test: [  16/39]  Time: 0.178 (0.226)  Loss:   0.191 ( 0.192)  Acc@1: 100.000 (100.000)  Acc@5: 100.000 (100.000)precision:   0.000 (  0.000)recall:   0.000 (  0.000)soec:   1.000 (  1.000)f1:   0.000 (  0.000)
2023-11-30 09:00:37,887 Test: [  17/39]  Time: 0.066 (0.218)  Loss:   0.189 ( 0.192)  Acc@1: 100.000 (100.000)  Acc@5: 100.000 (100.000)precision:   0.000 (  0.000)recall:   0.000 (  0.000)soec:   1.000 (  1.000)f1:   0.000 (  0.000)
2023-11-30 09:00:37,951 Test: [  18/39]  Time: 0.064 (0.209)  Loss:   0.191 ( 0.192)  Acc@1: 100.000 (100.000)  Acc@5: 100.000 (100.000)precision:   0.000 (  0.000)recall:   0.000 (  0.000)soec:   1.000 (  1.000)f1:   0.000 (  0.000)
2023-11-30 09:00:38,273 Test: [  19/39]  Time: 0.322 (0.215)  Loss:   0.190 ( 0.192)  Acc@1: 100.000 (100.000)  Acc@5: 100.000 (100.000)precision:   0.000 (  0.000)recall:   0.000 (  0.000)soec:   1.000 (  1.000)f1:   0.000 (  0.000)
2023-11-30 09:00:38,459 Test: [  20/39]  Time: 0.187 (0.214)  Loss:   0.190 ( 0.192)  Acc@1: 100.000 (100.000)  Acc@5: 100.000 (100.000)precision:   0.000 (  0.000)recall:   0.000 (  0.000)soec:   1.000 (  1.000)f1:   0.000 (  0.000)
2023-11-30 09:00:38,523 Test: [  21/39]  Time: 0.064 (0.207)  Loss:   0.188 ( 0.191)  Acc@1: 100.000 (100.000)  Acc@5: 100.000 (100.000)precision:   0.000 (  0.000)recall:   0.000 (  0.000)soec:   1.000 (  1.000)f1:   0.000 (  0.000)
2023-11-30 09:00:38,587 Test: [  22/39]  Time: 0.064 (0.201)  Loss:   1.338 ( 0.241)  Acc@1:  25.000 ( 96.739)  Acc@5: 100.000 (100.000)precision:   0.000 (  0.000)recall:   0.000 (  0.000)soec:   1.000 (  1.000)f1:   0.000 (  0.000)
2023-11-30 09:00:38,867 Test: [  23/39]  Time: 0.280 (0.204)  Loss:   1.739 ( 0.304)  Acc@1:   0.000 ( 92.708)  Acc@5: 100.000 (100.000)precision:   0.000 (  0.000)recall:   0.000 (  0.000)soec:   0.000 (  0.958)f1:   0.000 (  0.000)
2023-11-30 09:00:39,090 Test: [  24/39]  Time: 0.223 (0.205)  Loss:   1.737 ( 0.361)  Acc@1:   0.000 ( 89.000)  Acc@5: 100.000 (100.000)precision:   0.000 (  0.000)recall:   0.000 (  0.000)soec:   0.000 (  0.920)f1:   0.000 (  0.000)
2023-11-30 09:00:39,154 Test: [  25/39]  Time: 0.064 (0.199)  Loss:   1.747 ( 0.414)  Acc@1:   0.000 ( 85.577)  Acc@5: 100.000 (100.000)precision:   0.000 (  0.000)recall:   0.000 (  0.000)soec:   0.000 (  0.885)f1:   0.000 (  0.000)
2023-11-30 09:00:39,218 Test: [  26/39]  Time: 0.064 (0.194)  Loss:   1.740 ( 0.463)  Acc@1:   0.000 ( 82.407)  Acc@5: 100.000 (100.000)precision:   0.000 (  0.000)recall:   0.000 (  0.000)soec:   0.000 (  0.852)f1:   0.000 (  0.000)
2023-11-30 09:00:39,495 Test: [  27/39]  Time: 0.278 (0.197)  Loss:   1.746 ( 0.509)  Acc@1:   0.000 ( 79.464)  Acc@5: 100.000 (100.000)precision:   0.000 (  0.000)recall:   0.000 (  0.000)soec:   0.000 (  0.821)f1:   0.000 (  0.000)
2023-11-30 09:00:39,673 Test: [  28/39]  Time: 0.178 (0.197)  Loss:   1.752 ( 0.552)  Acc@1:   0.000 ( 76.724)  Acc@5: 100.000 (100.000)precision:   0.000 (  0.000)recall:   0.000 (  0.000)soec:   0.000 (  0.793)f1:   0.000 (  0.000)
2023-11-30 09:00:39,739 Test: [  29/39]  Time: 0.066 (0.192)  Loss:   1.752 ( 0.592)  Acc@1:   0.000 ( 74.167)  Acc@5: 100.000 (100.000)precision:   0.000 (  0.000)recall:   0.000 (  0.000)soec:   0.000 (  0.767)f1:   0.000 (  0.000)
2023-11-30 09:00:39,803 Test: [  30/39]  Time: 0.064 (0.188)  Loss:   1.746 ( 0.629)  Acc@1:   0.000 ( 71.774)  Acc@5: 100.000 (100.000)precision:   0.000 (  0.000)recall:   0.000 (  0.000)soec:   0.000 (  0.742)f1:   0.000 (  0.000)
2023-11-30 09:00:40,123 Test: [  31/39]  Time: 0.320 (0.192)  Loss:   1.754 ( 0.664)  Acc@1:   0.000 ( 69.531)  Acc@5: 100.000 (100.000)precision:   0.000 (  0.000)recall:   0.000 (  0.000)soec:   0.000 (  0.719)f1:   0.000 (  0.000)
2023-11-30 09:00:40,285 Test: [  32/39]  Time: 0.162 (0.191)  Loss:   1.737 ( 0.697)  Acc@1:   0.000 ( 67.424)  Acc@5: 100.000 (100.000)precision:   0.000 (  0.000)recall:   0.000 (  0.000)soec:   0.000 (  0.697)f1:   0.000 (  0.000)
2023-11-30 09:00:40,352 Test: [  33/39]  Time: 0.067 (0.188)  Loss:   1.746 ( 0.728)  Acc@1:   0.000 ( 65.441)  Acc@5: 100.000 (100.000)precision:   0.000 (  0.000)recall:   0.000 (  0.000)soec:   0.000 (  0.676)f1:   0.000 (  0.000)
2023-11-30 09:00:40,415 Test: [  34/39]  Time: 0.064 (0.184)  Loss:   1.739 ( 0.757)  Acc@1:   0.000 ( 63.571)  Acc@5: 100.000 (100.000)precision:   0.000 (  0.000)recall:   0.000 (  0.000)soec:   0.000 (  0.657)f1:   0.000 (  0.000)
2023-11-30 09:00:40,485 Test: [  35/39]  Time: 0.069 (0.181)  Loss:   1.751 ( 0.784)  Acc@1:   0.000 ( 61.806)  Acc@5: 100.000 (100.000)precision:   0.000 (  0.000)recall:   0.000 (  0.000)soec:   0.000 (  0.639)f1:   0.000 (  0.000)
2023-11-30 09:00:40,805 Test: [  36/39]  Time: 0.321 (0.185)  Loss:   1.703 ( 0.809)  Acc@1:   0.000 ( 60.135)  Acc@5: 100.000 (100.000)precision:   0.000 (  0.000)recall:   0.000 (  0.000)soec:   0.000 (  0.622)f1:   0.000 (  0.000)
2023-11-30 09:00:41,535 Test: [  37/39]  Time: 0.729 (0.199)  Loss:   1.480 ( 0.827)  Acc@1:   9.375 ( 58.799)  Acc@5: 100.000 (100.000)precision:   1.000 (  0.026)recall:   0.094 (  0.002)soec:   0.000 (  0.605)f1:   0.171 (  0.005)
2023-11-30 09:00:41,596 Test: [  38/39]  Time: 0.061 (0.195)  Loss:   1.540 ( 0.845)  Acc@1:   3.125 ( 57.372)  Acc@5: 100.000 (100.000)precision:   1.000 (  0.051)recall:   0.031 (  0.003)soec:   0.000 (  0.590)f1:   0.061 (  0.006)
2023-11-30 09:00:41,794 Test: [  39/39]  Time: 0.198 (0.196)  Loss:   1.305 ( 0.846)  Acc@1:   0.000 ( 57.280)  Acc@5: 100.000 (100.000)precision:   0.000 (  0.051)recall:   0.000 (  0.003)soec:   0.000 (  0.589)f1:   0.000 (  0.006)
2023-11-30 09:00:42,020 Current checkpoints:
 ('./output/train/20231130-090020-efficientnet_b0-259/checkpoint-0.pth.tar', 57.28)

2023-11-30 09:00:42,020 *** Best metric: 57.28 (epoch 0)
